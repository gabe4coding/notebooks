{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# From Zero to RAG: An Incremental, Hands-On Notebook\n\nWelcome to this comprehensive tutorial on building a Retrieval-Augmented Generation (RAG) pipeline from scratch! In this notebook, you'll learn how to create a complete RAG system incrementally, starting with basic keyword search and progressing to sophisticated semantic retrieval with re-ranking.\n\n## What You'll Learn\n- Build retrieval systems using TF-IDF, BM25, and semantic embeddings\n- Implement hybrid retrieval combining lexical and semantic approaches\n- Apply rank fusion techniques (Reciprocal Rank Fusion)\n- Use cross-encoder re-ranking for improved precision\n- Create an end-to-end RAG pipeline with generation\n\n## What Gets Built\nBy the end, you'll have a working RAG system that can answer questions about a synthetic knowledge base, complete with retrieval, re-ranking, and generation components.\n\n## Technical Constraints\n- **Python 3.10+** compatible code throughout\n- **Open-source models only** for embeddings and re-ranking (sentence-transformers, cross-encoders)\n- **Hugging Face Token for model access** required HF_TOKEN\n- **OpenAI SDK** used only for the final generation step; Needs OPENAI_API_KEY\n- All dependencies installable via pip","metadata":{}},{"cell_type":"code","source":"# Setup & Environment Check\nimport sys\nimport os\nimport subprocess\nimport importlib.util\n\n# Print Python version to verify compatibility\nprint(f\"Python version: {sys.version}\")\nif sys.version_info < (3, 10):\n    print(\"⚠️  Warning: This notebook requires Python 3.10 or higher\")\nelse:\n    print(\"✅ Python version compatible\")\n\n# Define required packages\nrequired_packages = [\n    'numpy',\n    'pandas', \n    'scikit-learn',\n    'rank_bm25',\n    'sentence-transformers',\n    'torch',\n    'faiss-cpu',\n    'tqdm',\n    'openai',\n    'python-dotenv'  # Added for loading .env files\n]\n\ndef install_package(package_name):\n    \"\"\"Install a package using pip programmatically\"\"\"\n    try:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])\n        print(f\"✅ Successfully installed {package_name}\")\n        return True\n    except subprocess.CalledProcessError:\n        print(f\"❌ Failed to install {package_name}\")\n        return False\n\ndef check_and_install_packages(packages):\n    \"\"\"Check if packages are available, install if missing\"\"\"\n    missing_packages = []\n    \n    # First pass: check what's missing\n    for package in packages:\n        # Handle special cases for import names vs package names\n        import_name = package\n        if package == 'scikit-learn':\n            import_name = 'sklearn'\n        elif package == 'faiss-cpu':\n            import_name = 'faiss'\n        elif package == 'rank_bm25':\n            import_name = 'rank_bm25'\n        elif package == 'python-dotenv':\n            import_name = 'dotenv'\n            \n        spec = importlib.util.find_spec(import_name)\n        if spec is None:\n            missing_packages.append(package)\n            print(f\"❌ {package} not found\")\n        else:\n            print(f\"✅ {package} available\")\n    \n    # Second pass: install missing packages\n    if missing_packages:\n        print(f\"\\n📦 Installing {len(missing_packages)} missing packages...\")\n        for package in missing_packages:\n            install_package(package)\n    \n    return missing_packages\n\n# Check and install packages\nmissing = check_and_install_packages(required_packages)\n\nprint(\"\\n🔄 Importing all packages...\")\ntry:\n    import numpy as np\n    import pandas as pd\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.metrics.pairwise import cosine_similarity\n    from rank_bm25 import BM25Okapi\n    from sentence_transformers import SentenceTransformer, CrossEncoder\n    import torch\n    try:\n        import faiss\n        FAISS_AVAILABLE = True\n    except ImportError:\n        from sklearn.neighbors import NearestNeighbors\n        FAISS_AVAILABLE = False\n        print(\"ℹ️  FAISS not available, will use sklearn NearestNeighbors\")\n    from tqdm import tqdm\n    from openai import OpenAI\n    from dotenv import load_dotenv\n    \n    print(\"✅ All imports successful!\")\n    \nexcept ImportError as e:\n    print(f\"❌ Import failed: {e}\")\n    print(\"Please restart the kernel and try again.\")\n\n# Load environment variables from .env file\nprint(\"\\n🔑 Loading environment variables...\")\nenv_loaded = load_dotenv()\nif env_loaded:\n    print(\"✅ .env file loaded successfully\")\nelse:\n    print(\"ℹ️  No .env file found or already loaded\")\n\n# Use Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nopenai_key = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\nif hf_token:\n    os.environ['HF_TOKEN'] = hf_token\n    print(\"✅ HF_TOKEN loaded from Kaggle secrets\")\nelse:\n    print(\"ℹ️  HF_TOKEN not found in Kaggle secrets\")\nif openai_key:\n    os.environ['OPENAI_API_KEY'] = openai_key\n    print(\"✅ OPENAI_API_KEY loaded from Kaggle secrets\")\nelse:\n    print(\"ℹ️  OPENAI_API_KEY not found in Kaggle secrets\")\n\n# Check for required API keys\nopenai_key = os.getenv('OPENAI_API_KEY')\nhf_token = os.getenv('HF_TOKEN')\n\nprint(\"\\n🔐 API Key Status:\")\nif openai_key:\n    print(f\"✅ OPENAI_API_KEY: Found (starts with: {openai_key[:10]}...)\")\nelse:\n    print(\"❌ OPENAI_API_KEY: Not found\")\n    print(\"   Set OPENAI_API_KEY in your .env file or environment variables\")\n\nif hf_token:\n    print(f\"✅ HF_TOKEN: Found (starts with: {hf_token[:10]}...)\")\nelse:\n    print(\"❌ HF_TOKEN: Not found\")\n    print(\"   Set HF_TOKEN in your .env file or environment variables\")\n\n# Set global random seeds for reproducibility\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n    \nprint(\"\\n🎯 Random seeds set for reproducibility\")\nprint(\"🚀 Environment ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:48.167073Z","iopub.execute_input":"2025-09-24T14:23:48.169279Z","iopub.status.idle":"2025-09-24T14:23:52.888105Z","shell.execute_reply.started":"2025-09-24T14:23:48.169123Z","shell.execute_reply":"2025-09-24T14:23:52.886912Z"}},"outputs":[{"name":"stdout","text":"Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n✅ Python version compatible\n✅ numpy available\n✅ pandas available\n✅ scikit-learn available\n✅ rank_bm25 available\n❌ sentence-transformers not found\n✅ torch available\n✅ faiss-cpu available\n✅ tqdm available\n✅ openai available\n✅ python-dotenv available\n\n📦 Installing 1 missing packages...\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\n✅ Successfully installed sentence-transformers\n\n🔄 Importing all packages...\n✅ All imports successful!\n\n🔑 Loading environment variables...\nℹ️  No .env file found or already loaded\n✅ HF_TOKEN loaded from Kaggle secrets\n✅ OPENAI_API_KEY loaded from Kaggle secrets\n\n🔐 API Key Status:\n✅ OPENAI_API_KEY: Found (starts with: sk-proj-io...)\n✅ HF_TOKEN: Found (starts with: hf_nIWLRsu...)\n\n🎯 Random seeds set for reproducibility\n🚀 Environment ready!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## What is RAG?\n\n**Retrieval-Augmented Generation (RAG)** combines information retrieval with text generation to create more accurate, grounded responses. Instead of relying solely on a language model's training data, RAG first retrieves relevant documents from a knowledge base, then uses those documents to generate answers.\n\n### Core Components\n1. **Indexing**: Preprocessing and storing documents for efficient retrieval\n2. **Retrieval**: Finding relevant documents given a query\n3. **Fusion**: Combining results from multiple retrieval methods\n4. **Re-ranking**: Refining the order of retrieved documents\n5. **Generation**: Creating answers using retrieved context\n\n### Key Benefits\n- **Reduces hallucinations** by grounding responses in actual documents\n- **Enables up-to-date information** without retraining models\n- **Provides citations** for transparency and verification\n- **Scales efficiently** to large knowledge bases\n\n### Trade-offs\nRAG adds complexity and latency but dramatically improves factual accuracy and allows dynamic knowledge updates. The retrieval quality directly impacts the final answer quality.","metadata":{}},{"cell_type":"markdown","source":"## Dataset Preparation\n\nQuality retrieval starts with quality data. Clean, well-structured documents are essential for effective RAG systems. Each document should have consistent fields and clear, focused content.\n\n### Key Principles\n- **Structured format**: Use consistent fields (id, title, text) for easy processing\n- **Appropriate granularity**: Documents should be focused but comprehensive\n- **Clean text**: Remove formatting artifacts, normalize whitespace\n- **Diverse content**: Include varied topics to test retrieval robustness\n\n### Our Synthetic Corpus\nWe'll create a small but diverse dataset spanning multiple domains (astronomy, cooking, programming, history, health, sports). This allows us to test different retrieval methods on varied content types. Including some near-duplicates and paraphrases helps evaluate robustness to semantic similarity.\n\n### Licensing Note\nWhen using real data, always verify licensing terms and respect copyright. Our synthetic dataset avoids these concerns while providing realistic testing scenarios.\n\n**Deterministic seeds** ensure reproducible results across runs, crucial for comparing retrieval methods fairly.","metadata":{}},{"cell_type":"code","source":"# Create synthetic corpus for tutorial\nimport pandas as pd\nimport os\n\n# Create data directory if it doesn't exist\nos.makedirs('./data', exist_ok=True)\n\n# Generate synthetic documents for demonstration\ndocuments = [\n    # Astronomy documents\n    {\"id\": \"ast_001\", \"title\": \"Understanding Black Holes\", \n     \"text\": \"Black holes are regions of spacetime where gravity is so strong that nothing, including light, can escape once it crosses the event horizon. The event horizon is the boundary beyond which escape becomes impossible. Black holes form when massive stars collapse under their own gravity at the end of their lifecycle. The singularity at the center represents a point where spacetime curvature becomes infinite.\"},\n    \n    {\"id\": \"ast_002\", \"title\": \"The Life Cycle of Stars\", \n     \"text\": \"Stars are born from clouds of gas and dust called nebulae. Through gravitational collapse, the core temperature rises until nuclear fusion begins, converting hydrogen into helium and releasing enormous amounts of energy. A star's mass determines its lifecycle - more massive stars burn brighter and die younger, while smaller stars can burn for billions of years.\"},\n    \n    {\"id\": \"ast_003\", \"title\": \"Solar System Formation\", \n     \"text\": \"The solar system formed approximately 4.6 billion years ago from the gravitational collapse of a molecular cloud. The Sun formed at the center while leftover material formed a protoplanetary disk. Through accretion and collisions, planetary embryos grew into the planets we know today. The process explains the orbital characteristics and composition differences between inner rocky planets and outer gas giants.\"},\n    \n    {\"id\": \"ast_004\", \"title\": \"Exoplanet Detection Methods\", \n     \"text\": \"Astronomers use several methods to detect exoplanets. The transit method observes the dimming of a star as a planet passes in front of it. The radial velocity method detects wobbles in a star's motion caused by an orbiting planet's gravitational pull. Direct imaging captures light from the planet itself, though this is challenging due to the brightness difference between stars and planets.\"},\n    \n    {\"id\": \"ast_005\", \"title\": \"Dark Matter and Dark Energy\", \n     \"text\": \"Dark matter makes up approximately 27% of the universe but doesn't interact electromagnetically, making it invisible to direct observation. Its existence is inferred from gravitational effects on visible matter and large-scale structure formation. Dark energy, comprising about 68% of the universe, drives the accelerating expansion of spacetime itself, counteracting gravity on cosmic scales.\"},\n    \n    # Cooking documents\n    {\"id\": \"cook_001\", \"title\": \"Essential Knife Skills\", \n     \"text\": \"Proper knife skills form the foundation of cooking efficiency and safety. The chef's knife should be held with a pinch grip, controlling the blade with thumb and forefinger. The guiding hand forms a claw to protect fingertips while providing stability. Consistent cuts ensure even cooking - brunoise for small dice, julienne for thin strips, and chiffonade for leafy herbs.\"},\n    \n    {\"id\": \"cook_002\", \"title\": \"Understanding Heat and Cooking Methods\", \n     \"text\": \"Heat transfer occurs through conduction, convection, and radiation in cooking. Dry heat methods like roasting and grilling develop flavor through the Maillard reaction, creating complex tastes and aromas. Moist heat methods like braising and steaming are gentler, preserving delicate textures. Understanding heat control prevents overcooking and ensures proteins remain tender and juicy.\"},\n    \n    {\"id\": \"cook_003\", \"title\": \"Building Flavor Profiles\", \n     \"text\": \"Flavor development starts with aromatics - onions, garlic, and celery form the foundation of many cuisines. Layering flavors throughout the cooking process creates depth and complexity. Seasoning should happen in stages, not just at the end. Acid brightens dishes, fat carries flavors, and herbs add freshness. Understanding how ingredients interact helps create balanced, memorable meals.\"},\n    \n    {\"id\": \"cook_004\", \"title\": \"Sauce Making Fundamentals\", \n     \"text\": \"Classic mother sauces provide the foundation for countless variations. Roux-based sauces like béchamel use equal parts fat and flour to create smooth, creamy textures. Emulsification binds oil and water-based ingredients, as seen in mayonnaise and hollandaise. Reduction concentrates flavors by evaporating liquid, creating intensely flavored pan sauces and glazes.\"},\n    \n    {\"id\": \"cook_005\", \"title\": \"Baking Science and Techniques\", \n     \"text\": \"Baking relies on precise chemical reactions between ingredients. Gluten development in flour provides structure, while leavening agents create lift through gas production. Temperature control affects texture - higher heat creates crustier exteriors while lower heat ensures even cooking. Understanding ingredient ratios and their functions enables consistent results and successful recipe modifications.\"},\n    \n    # Python programming documents  \n    {\"id\": \"py_001\", \"title\": \"Object-Oriented Programming Concepts\", \n     \"text\": \"Object-oriented programming organizes code around objects rather than functions. Classes serve as blueprints defining attributes and methods, while objects are specific instances of classes. Encapsulation hides internal implementation details, inheritance enables code reuse through class hierarchies, and polymorphism allows different objects to respond to the same interface in their own way.\"},\n    \n    {\"id\": \"py_002\", \"title\": \"Efficient Data Processing with Pandas\", \n     \"text\": \"Pandas provides powerful data structures and operations for manipulating structured data. DataFrames offer two-dimensional labeled data structures similar to spreadsheets. Vectorized operations perform element-wise calculations efficiently without explicit loops. Groupby operations enable split-apply-combine workflows, while merge and join operations combine datasets based on common keys.\"},\n    \n    {\"id\": \"py_003\", \"title\": \"Asynchronous Programming Patterns\", \n     \"text\": \"Asynchronous programming enables concurrent execution without blocking operations. The async/await syntax provides a clean way to write asynchronous code that looks synchronous. Event loops manage the execution of asynchronous tasks, while coroutines are functions that can be paused and resumed. This approach is particularly effective for I/O-bound operations like web requests or database queries.\"},\n    \n    {\"id\": \"py_004\", \"title\": \"Machine Learning Pipeline Design\", \n     \"text\": \"ML pipelines automate the workflow from raw data to trained models. Data preprocessing includes cleaning, feature engineering, and transformation steps. Cross-validation ensures model generalization, while hyperparameter tuning optimizes model performance. Production pipelines must handle data drift, model monitoring, and automated retraining to maintain accuracy over time.\"},\n    \n    {\"id\": \"py_005\", \"title\": \"API Development with FastAPI\", \n     \"text\": \"FastAPI enables rapid development of high-performance web APIs with automatic OpenAPI documentation. Type hints provide automatic validation and serialization of request/response data. Dependency injection enables clean separation of concerns and easier testing. Async support handles concurrent requests efficiently, while middleware provides cross-cutting functionality like authentication and logging.\"},\n    \n    # History documents\n    {\"id\": \"hist_001\", \"title\": \"The Industrial Revolution\", \n     \"text\": \"The Industrial Revolution transformed society from agricultural to manufacturing economies between 1760 and 1840. Steam power revolutionized transportation and production, while factory systems centralized manufacturing. Urbanization accelerated as workers moved from rural areas to industrial cities. These changes brought both economic growth and social challenges, including harsh working conditions and environmental pollution.\"},\n    \n    {\"id\": \"hist_002\", \"title\": \"Ancient Civilizations and Trade\", \n     \"text\": \"Ancient trade routes connected distant civilizations, facilitating cultural and technological exchange. The Silk Road linked Asia and Europe, carrying not just silk but ideas, religions, and innovations. Maritime trade in the Mediterranean enabled the rise of powerful city-states like Venice and Genoa. These networks spread agricultural techniques, metalworking, and writing systems across vast distances.\"},\n    \n    {\"id\": \"hist_003\", \"title\": \"The Renaissance Period\", \n     \"text\": \"The Renaissance marked a period of renewed interest in classical learning, art, and humanism from the 14th to 17th centuries. Artists like Leonardo da Vinci and Michelangelo revolutionized artistic techniques and scientific observation. The printing press democratized knowledge, while patronage systems supported artistic and intellectual pursuits. This cultural movement laid foundations for modern scientific methods and artistic expression.\"},\n    \n    {\"id\": \"hist_004\", \"title\": \"World War Impact on Society\", \n     \"text\": \"World Wars I and II fundamentally reshaped global society, politics, and technology. Total war mobilized entire populations, advancing manufacturing and medical techniques. Women entered the workforce in unprecedented numbers, challenging traditional gender roles. The wars accelerated decolonization movements and led to new international organizations aimed at preventing future conflicts.\"},\n    \n    {\"id\": \"hist_005\", \"title\": \"The Cold War Era\", \n     \"text\": \"The Cold War (1945-1991) defined international relations through ideological competition between capitalism and communism. Nuclear weapons created a balance of terror, preventing direct conflict while fueling proxy wars. The space race demonstrated technological capabilities, while cultural exchanges like jazz and cinema influenced global perspectives. The period ended with economic reforms and the dissolution of the Soviet Union.\"},\n    \n    # Health documents\n    {\"id\": \"heal_001\", \"title\": \"Nutrition and Metabolism\", \n     \"text\": \"Metabolism encompasses all chemical processes that maintain life, including catabolism (breaking down molecules for energy) and anabolism (building complex molecules). Macronutrients - carbohydrates, proteins, and fats - provide energy and building blocks for cellular processes. Micronutrients like vitamins and minerals act as cofactors in enzymatic reactions essential for health.\"},\n    \n    {\"id\": \"heal_002\", \"title\": \"Cardiovascular Health\", \n     \"text\": \"The cardiovascular system pumps blood through a network of vessels, delivering oxygen and nutrients while removing waste products. Regular exercise strengthens the heart muscle and improves circulation. Diet affects cardiovascular health through cholesterol levels, blood pressure, and inflammation. Preventive measures include maintaining healthy weight, avoiding smoking, and managing stress levels.\"},\n    \n    {\"id\": \"heal_003\", \"title\": \"Mental Health and Wellness\", \n     \"text\": \"Mental health encompasses emotional, psychological, and social well-being, affecting thoughts, feelings, and behaviors. Stress management techniques like meditation and deep breathing activate the parasympathetic nervous system. Social connections and meaningful relationships provide emotional support and resilience. Professional treatment options include therapy, medication, and lifestyle modifications tailored to individual needs.\"},\n    \n    {\"id\": \"heal_004\", \"title\": \"Sleep and Recovery\", \n     \"text\": \"Sleep plays a crucial role in physical and mental health through multiple sleep cycles of REM and non-REM stages. During sleep, the brain consolidates memories and clears metabolic waste products. Growth hormone release peaks during deep sleep, supporting tissue repair and immune function. Sleep hygiene practices like consistent schedules and optimal environment promote quality rest.\"},\n    \n    {\"id\": \"heal_005\", \"title\": \"Immune System Function\", \n     \"text\": \"The immune system defends against pathogens through innate and adaptive responses. White blood cells identify and eliminate threats, while antibodies provide specific protection against previously encountered antigens. Vaccination trains the immune system to recognize pathogens without causing disease. Lifestyle factors like nutrition, exercise, and stress management influence immune system effectiveness.\"},\n    \n    # Sports documents\n    {\"id\": \"sport_001\", \"title\": \"Athletic Performance Optimization\", \n     \"text\": \"Peak athletic performance requires balancing training stress, recovery, and adaptation. Periodization systematically varies training intensity and volume to peak for competitions. Sport-specific training develops the energy systems and movement patterns most relevant to performance. Recovery protocols including sleep, nutrition, and active recovery prevent overtraining and reduce injury risk.\"},\n    \n    {\"id\": \"sport_002\", \"title\": \"Sports Psychology and Mental Training\", \n     \"text\": \"Mental training enhances athletic performance through focus, confidence, and stress management techniques. Visualization helps athletes mentally rehearse successful performance and overcome challenges. Goal setting provides direction and motivation, while self-talk influences confidence and concentration. Handling pressure situations requires developing coping strategies and maintaining optimal arousal levels.\"},\n    \n    {\"id\": \"sport_003\", \"title\": \"Injury Prevention Strategies\", \n     \"text\": \"Injury prevention combines proper warm-up, strength training, and biomechanical awareness. Dynamic warm-ups prepare muscles and joints for activity-specific movements. Strength imbalances increase injury risk, particularly between opposing muscle groups. Recovery time between training sessions allows tissues to adapt and repair, reducing the likelihood of overuse injuries.\"},\n    \n    {\"id\": \"sport_004\", \"title\": \"Strength Training Principles\", \n     \"text\": \"Effective strength training follows progressive overload, gradually increasing resistance to stimulate adaptation. Compound exercises like squats and deadlifts work multiple muscle groups efficiently. Training frequency, volume, and intensity must be balanced for optimal results. Proper form prevents injury and ensures targeted muscle activation during resistance exercises.\"},\n    \n    {\"id\": \"sport_005\", \"title\": \"Endurance Training Methodologies\", \n     \"text\": \"Endurance training improves the body's ability to sustain prolonged physical activity. Training zones based on heart rate or power output optimize different energy systems. Base training builds aerobic capacity, while high-intensity intervals improve lactate threshold. Periodization varies training stress to promote adaptation while preventing burnout and overtraining syndrome.\"}\n]\n\n# Convert to pandas DataFrame for easy manipulation\ncorpus_df = pd.DataFrame(documents)\n\nprint(f\"📊 Created synthetic corpus with {len(corpus_df)} documents\")\nprint(f\"📂 Domains covered: {len(corpus_df['id'].str[:4].unique())} unique prefixes\")\nprint(f\"📏 Text length range: {corpus_df['text'].str.len().min()} - {corpus_df['text'].str.len().max()} characters\")\n\n# Show distribution by domain using DataFrame\ndomain_counts = corpus_df['id'].str[:4].value_counts()\ndomain_names = {\n    'ast_': 'Astronomy',\n    'cook': 'Cooking', \n    'py_0': 'Python/Programming',\n    'hist': 'History',\n    'heal': 'Health',\n    'spor': 'Sports'\n}\n\n# Create domain distribution DataFrame\ndomain_df = pd.DataFrame({\n    'Domain': [domain_names.get(prefix, prefix) for prefix in domain_counts.index],\n    'Document Count': domain_counts.values,\n    'Prefix': domain_counts.index\n})\n\nprint(\"\\n📈 Documents per domain:\")\ndisplay(domain_df[['Domain', 'Document Count']])\n\n# Save to CSV for reuse throughout the notebook\ncorpus_df.to_csv('./data/corpus.csv', index=False)\nprint(\"💾 Corpus saved to ./data/corpus.csv\")\n\n# Display sample documents as DataFrame\nsample_df = corpus_df[['id', 'title', 'text']].head(3).copy()\nsample_df['text_preview'] = sample_df['text'].str[:100] + \"...\"\nsample_display = sample_df[['id', 'title', 'text_preview']].copy()\nsample_display.columns = ['ID', 'Title', 'Text Preview']\n\nprint(\"\\n📋 Sample documents:\")\ndisplay(sample_display)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:52.890137Z","iopub.execute_input":"2025-09-24T14:23:52.890449Z","iopub.status.idle":"2025-09-24T14:23:53.006218Z","shell.execute_reply.started":"2025-09-24T14:23:52.890428Z","shell.execute_reply":"2025-09-24T14:23:53.004976Z"}},"outputs":[{"name":"stdout","text":"📊 Created synthetic corpus with 30 documents\n📂 Domains covered: 6 unique prefixes\n📏 Text length range: 363 - 444 characters\n\n📈 Documents per domain:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               Domain  Document Count\n0           Astronomy               5\n1             Cooking               5\n2  Python/Programming               5\n3             History               5\n4              Health               5\n5              Sports               5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Domain</th>\n      <th>Document Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Astronomy</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cooking</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Python/Programming</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>History</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Health</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sports</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"💾 Corpus saved to ./data/corpus.csv\n\n📋 Sample documents:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        ID                      Title  \\\n0  ast_001  Understanding Black Holes   \n1  ast_002    The Life Cycle of Stars   \n2  ast_003     Solar System Formation   \n\n                                        Text Preview  \n0  Black holes are regions of spacetime where gra...  \n1  Stars are born from clouds of gas and dust cal...  \n2  The solar system formed approximately 4.6 bill...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Title</th>\n      <th>Text Preview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>Black holes are regions of spacetime where gra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ast_002</td>\n      <td>The Life Cycle of Stars</td>\n      <td>Stars are born from clouds of gas and dust cal...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ast_003</td>\n      <td>Solar System Formation</td>\n      <td>The solar system formed approximately 4.6 bill...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## TF-IDF: Term Frequency-Inverse Document Frequency\n\n**TF-IDF** is a fundamental text retrieval technique that scores documents based on term importance. It combines two concepts:\n- **Term Frequency (TF)**: How often a term appears in a document\n- **Inverse Document Frequency (IDF)**: How rare a term is across the entire corpus\n\n### Intuition\nWords that appear frequently in a document but rarely across the corpus are most important for distinguishing that document. Common words like \"the\" and \"and\" get low scores, while specific terms get higher scores.\n\n### How It Works\nDocuments are converted to vectors where each dimension represents a unique term's TF-IDF score. Query similarity is computed using cosine similarity between the query vector and document vectors.\n\n### Advantages\n- **Fast and interpretable**: Clear scoring rationale\n- **No training required**: Works immediately on any corpus\n- **Memory efficient**: Sparse vectors for large vocabularies\n\n### Limitations\n- **Vocabulary mismatch**: Can't match synonyms (\"car\" vs \"automobile\")\n- **Word order ignored**: \"dog bites man\" = \"man bites dog\"\n- **No semantic understanding**: Relies purely on exact word matches","metadata":{}},{"cell_type":"code","source":"# TF-IDF retrieval implementation using scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Initialize TF-IDF vectorizer with optimized parameters\n# - Use both unigrams and bigrams to capture phrases like \"black holes\"\n# - Convert to lowercase for normalization\n# - Remove English stop words to focus on meaningful terms\n# - Set max_features to control vocabulary size and computation\ntfidf_vectorizer = TfidfVectorizer(\n    ngram_range=(1, 2),  # Include both single words and word pairs\n    lowercase=True,      # Normalize case\n    stop_words='english', # Remove common words like 'the', 'and'\n    max_features=10000,  # Limit vocabulary size for efficiency\n    min_df=1,            # Include terms that appear in at least 1 document\n    max_df=0.8           # Exclude terms that appear in >80% of documents\n)\n\n# Fit the vectorizer on our corpus and transform texts to TF-IDF vectors\nprint(\"🔄 Building TF-IDF matrix...\")\ntfidf_matrix = tfidf_vectorizer.fit_transform(corpus_df['text'])\n\nprint(f\"📊 TF-IDF matrix shape: {tfidf_matrix.shape}\")\nprint(f\"📝 Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")\nprint(f\"💾 Matrix sparsity: {(1 - tfidf_matrix.nnz / tfidf_matrix.size) * 100:.1f}% zeros\")\n\ndef query_tfidf(query_text, top_k=5):\n    \"\"\"\n    Retrieve documents using TF-IDF similarity.\n    \n    Args:\n        query_text (str): The search query\n        top_k (int): Number of top results to return\n    \n    Returns:\n        list: Tuples of (document_index, similarity_score, document_info)\n    \"\"\"\n    # Transform query using the same vectorizer fitted on corpus\n    query_vector = tfidf_vectorizer.transform([query_text])\n    \n    # Compute cosine similarity between query and all documents\n    # Cosine similarity ranges from 0 (no similarity) to 1 (identical)\n    similarity_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n    \n    # Get indices of top-k most similar documents\n    top_indices = similarity_scores.argsort()[-top_k:][::-1]\n    \n    # Build results with document info and scores\n    results = []\n    for idx in top_indices:\n        doc_info = {\n            'id': corpus_df.iloc[idx]['id'],\n            'title': corpus_df.iloc[idx]['title'],\n            'text': corpus_df.iloc[idx]['text']\n        }\n        results.append((idx, similarity_scores[idx], doc_info))\n    \n    return results\n\n# Test TF-IDF retrieval with example queries\ntest_queries = [\n    \"black holes and event horizons\",\n    \"python programming decorators\"\n]\n\nprint(\"\\n🔍 Testing TF-IDF retrieval:\")\nfor query in test_queries:\n    print(f\"\\n📋 Query: '{query}'\")\n    results = query_tfidf(query, top_k=5)\n    \n    print(\"Top 5 results:\")\n    for rank, (idx, score, doc_info) in enumerate(results, 1):\n        print(f\"  {rank}. [{doc_info['id']}] {doc_info['title']} (score: {score:.3f})\")\n        # Show first 100 characters of text as snippet\n        snippet = doc_info['text'][:100] + '...' if len(doc_info['text']) > 100 else doc_info['text']\n        print(f\"      {snippet}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:53.006978Z","iopub.execute_input":"2025-09-24T14:23:53.007386Z","iopub.status.idle":"2025-09-24T14:23:53.059003Z","shell.execute_reply.started":"2025-09-24T14:23:53.007362Z","shell.execute_reply":"2025-09-24T14:23:53.057750Z"}},"outputs":[{"name":"stdout","text":"🔄 Building TF-IDF matrix...\n📊 TF-IDF matrix shape: (30, 1938)\n📝 Vocabulary size: 1938\n💾 Matrix sparsity: 0.0% zeros\n\n🔍 Testing TF-IDF retrieval:\n\n📋 Query: 'black holes and event horizons'\nTop 5 results:\n  1. [ast_001] Understanding Black Holes (score: 0.442)\n      Black holes are regions of spacetime where gravity is so strong that nothing, including light, can e...\n  2. [py_003] Asynchronous Programming Patterns (score: 0.046)\n      Asynchronous programming enables concurrent execution without blocking operations. The async/await s...\n  3. [sport_004] Strength Training Principles (score: 0.000)\n      Effective strength training follows progressive overload, gradually increasing resistance to stimula...\n  4. [ast_002] The Life Cycle of Stars (score: 0.000)\n      Stars are born from clouds of gas and dust called nebulae. Through gravitational collapse, the core ...\n  5. [ast_003] Solar System Formation (score: 0.000)\n      The solar system formed approximately 4.6 billion years ago from the gravitational collapse of a mol...\n\n📋 Query: 'python programming decorators'\nTop 5 results:\n  1. [py_001] Object-Oriented Programming Concepts (score: 0.102)\n      Object-oriented programming organizes code around objects rather than functions. Classes serve as bl...\n  2. [py_003] Asynchronous Programming Patterns (score: 0.100)\n      Asynchronous programming enables concurrent execution without blocking operations. The async/await s...\n  3. [sport_005] Endurance Training Methodologies (score: 0.000)\n      Endurance training improves the body's ability to sustain prolonged physical activity. Training zone...\n  4. [sport_004] Strength Training Principles (score: 0.000)\n      Effective strength training follows progressive overload, gradually increasing resistance to stimula...\n  5. [ast_002] The Life Cycle of Stars (score: 0.000)\n      Stars are born from clouds of gas and dust called nebulae. Through gravitational collapse, the core ...\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## BM25: Best Matching 25\n\n**BM25** is a probabilistic ranking function that often outperforms TF-IDF for information retrieval. It improves upon TF-IDF by addressing two key limitations:\n\n### Key Improvements\n1. **Term Saturation**: TF-IDF scores increase linearly with term frequency, but BM25 uses a saturation function. After a certain point, additional occurrences contribute less to the score.\n\n2. **Document Length Normalization**: BM25 adjusts for document length, preventing longer documents from having unfair advantages simply due to more term occurrences.\n\n### Parameters\n- **k1** (typically 1.2-2.0): Controls term frequency saturation\n- **b** (typically 0.75): Controls document length normalization strength\n\n### When BM25 Excels\nBM25 typically outperforms TF-IDF for keyword search, especially with:\n- Varied document lengths\n- Collections where term frequency patterns matter\n- Traditional information retrieval tasks\n\nBoth TF-IDF and BM25 are **lexical** methods—they rely on exact word matches and don't understand semantics.","metadata":{}},{"cell_type":"code","source":"# BM25 retrieval implementation using rank_bm25\nfrom rank_bm25 import BM25Okapi\nimport string\nimport re\n\ndef simple_tokenizer(text):\n    \"\"\"\n    Simple tokenizer for BM25 preprocessing.\n    Converts to lowercase, removes punctuation, and splits on whitespace.\n    \n    Args:\n        text (str): Input text to tokenize\n    \n    Returns:\n        list: List of tokens\n    \"\"\"\n    # Convert to lowercase for case-insensitive matching\n    text = text.lower()\n    \n    # Remove punctuation using regex (keeps alphanumeric and spaces)\n    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n    \n    # Split on whitespace and filter empty strings\n    tokens = [token for token in text.split() if token]\n    \n    return tokens\n\n# Tokenize all documents in the corpus for BM25\nprint(\"🔄 Tokenizing corpus for BM25...\")\ntokenized_corpus = [simple_tokenizer(doc_text) for doc_text in corpus_df['text']]\n\n# Initialize BM25 with default parameters (k1=1.2, b=0.75)\n# These are well-tested values that work well across many domains\nbm25 = BM25Okapi(tokenized_corpus)\n\nprint(f\"📊 BM25 index built for {len(tokenized_corpus)} documents\")\nprint(f\"📝 Average document length: {np.mean([len(doc) for doc in tokenized_corpus]):.1f} tokens\")\n\ndef query_bm25(query_text, top_k=5):\n    \"\"\"\n    Retrieve documents using BM25 scoring.\n    \n    Args:\n        query_text (str): The search query\n        top_k (int): Number of top results to return\n    \n    Returns:\n        list: Tuples of (document_index, bm25_score, document_info)\n    \"\"\"\n    # Tokenize query using same tokenizer as corpus\n    query_tokens = simple_tokenizer(query_text)\n    \n    # Get BM25 scores for all documents\n    # Higher scores indicate better matches\n    bm25_scores = bm25.get_scores(query_tokens)\n    \n    # Get indices of top-k highest scoring documents\n    top_indices = np.argsort(bm25_scores)[-top_k:][::-1]\n    \n    # Build results with document info and scores\n    results = []\n    for idx in top_indices:\n        doc_info = {\n            'id': corpus_df.iloc[idx]['id'],\n            'title': corpus_df.iloc[idx]['title'],\n            'text': corpus_df.iloc[idx]['text']\n        }\n        results.append((idx, bm25_scores[idx], doc_info))\n    \n    return results\n\n# Compare BM25 vs TF-IDF on the same queries\ncomparison_queries = [\n    \"black holes event horizon\",\n    \"python decorators function behavior\",\n    \"exercise cardiovascular health\"\n]\n\nprint(\"\\n🔍 Comparing BM25 vs TF-IDF retrieval:\")\nfor query in comparison_queries:\n    print(f\"\\n📋 Query: '{query}'\")\n    \n    # Get results from both methods\n    bm25_results = query_bm25(query, top_k=3)\n    tfidf_results = query_tfidf(query, top_k=3)\n    \n    print(\"\\n🏆 BM25 Top 3:\")\n    for rank, (idx, score, doc_info) in enumerate(bm25_results, 1):\n        print(f\"  {rank}. [{doc_info['id']}] {doc_info['title']} (BM25: {score:.2f})\")\n    \n    print(\"\\n📊 TF-IDF Top 3:\")\n    for rank, (idx, score, doc_info) in enumerate(tfidf_results, 1):\n        print(f\"  {rank}. [{doc_info['id']}] {doc_info['title']} (TF-IDF: {score:.3f})\")\n    \n    # Show overlap between methods\n    bm25_ids = {doc_info['id'] for _, _, doc_info in bm25_results}\n    tfidf_ids = {doc_info['id'] for _, _, doc_info in tfidf_results}\n    overlap = bm25_ids.intersection(tfidf_ids)\n    print(f\"\\n🔗 Overlap: {len(overlap)}/3 documents match between methods\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:53.061619Z","iopub.execute_input":"2025-09-24T14:23:53.061886Z","iopub.status.idle":"2025-09-24T14:23:53.088213Z","shell.execute_reply.started":"2025-09-24T14:23:53.061865Z","shell.execute_reply":"2025-09-24T14:23:53.087194Z"}},"outputs":[{"name":"stdout","text":"🔄 Tokenizing corpus for BM25...\n📊 BM25 index built for 30 documents\n📝 Average document length: 52.9 tokens\n\n🔍 Comparing BM25 vs TF-IDF retrieval:\n\n📋 Query: 'black holes event horizon'\n\n🏆 BM25 Top 3:\n  1. [ast_001] Understanding Black Holes (BM25: 15.22)\n  2. [py_003] Asynchronous Programming Patterns (BM25: 2.35)\n  3. [sport_004] Strength Training Principles (BM25: 0.00)\n\n📊 TF-IDF Top 3:\n  1. [ast_001] Understanding Black Holes (TF-IDF: 0.546)\n  2. [py_003] Asynchronous Programming Patterns (TF-IDF: 0.037)\n  3. [sport_004] Strength Training Principles (TF-IDF: 0.000)\n\n🔗 Overlap: 3/3 documents match between methods\n\n📋 Query: 'python decorators function behavior'\n\n🏆 BM25 Top 3:\n  1. [heal_004] Sleep and Recovery (BM25: 2.90)\n  2. [sport_005] Endurance Training Methodologies (BM25: 0.00)\n  3. [py_004] Machine Learning Pipeline Design (BM25: 0.00)\n\n📊 TF-IDF Top 3:\n  1. [heal_004] Sleep and Recovery (TF-IDF: 0.100)\n  2. [sport_005] Endurance Training Methodologies (TF-IDF: 0.000)\n  3. [py_004] Machine Learning Pipeline Design (TF-IDF: 0.000)\n\n🔗 Overlap: 3/3 documents match between methods\n\n📋 Query: 'exercise cardiovascular health'\n\n🏆 BM25 Top 3:\n  1. [heal_002] Cardiovascular Health (BM25: 8.65)\n  2. [heal_005] Immune System Function (BM25: 2.50)\n  3. [heal_001] Nutrition and Metabolism (BM25: 1.87)\n\n📊 TF-IDF Top 3:\n  1. [heal_002] Cardiovascular Health (TF-IDF: 0.273)\n  2. [heal_005] Immune System Function (TF-IDF: 0.051)\n  3. [heal_001] Nutrition and Metabolism (TF-IDF: 0.037)\n\n🔗 Overlap: 3/3 documents match between methods\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Embeddings: Semantic Vector Representations\n\n**Embeddings** represent text as dense vectors in high-dimensional space where semantically similar texts are close together. Unlike lexical methods (TF-IDF, BM25), embeddings can match concepts even with different vocabulary.\n\n### Key Advantages\n- **Semantic understanding**: Matches \"car\" with \"automobile\"\n- **Cross-lingual capability**: Can work across languages\n- **Context awareness**: Considers word relationships and context\n\n### Vector Similarity\nCosine similarity measures the angle between vectors, ranging from -1 to 1. Values closer to 1 indicate higher semantic similarity.\n\n### Trade-offs\n- **Computational cost**: Embedding models require more resources\n- **Model dependence**: Quality depends on training data and architecture\n- **Interpretability**: Harder to understand why documents match\n\n### Approximate Nearest Neighbors (ANN)\nFor large corpora, exact similarity search becomes slow. ANN algorithms like FAISS provide fast approximate search with minimal accuracy loss.\n\n**Privacy note**: Using local models keeps data on your machine, unlike API-based embedding services.","metadata":{}},{"cell_type":"code","source":"# Text chunking for better embedding performance\n# Chunking breaks long documents into smaller, focused pieces\n# This improves embedding quality and allows more precise retrieval\n\ndef chunk_text(text, chunk_size_words=180, overlap_words=30):\n    \"\"\"\n    Split text into overlapping chunks of specified word count.\n    Overlap helps maintain context across chunk boundaries.\n    \n    Args:\n        text (str): Input text to chunk\n        chunk_size_words (int): Target words per chunk\n        overlap_words (int): Words to overlap between chunks\n    \n    Returns:\n        list: List of text chunks\n    \"\"\"\n    words = text.split()\n    \n    # If text is shorter than chunk size, return as single chunk\n    if len(words) <= chunk_size_words:\n        return [text]\n    \n    chunks = []\n    start = 0\n    \n    while start < len(words):\n        # Define chunk end, ensuring we don't exceed word count\n        end = min(start + chunk_size_words, len(words))\n        \n        # Extract chunk and join words back to text\n        chunk_words = words[start:end]\n        chunk_text = ' '.join(chunk_words)\n        chunks.append(chunk_text)\n        \n        # Move start position, accounting for overlap\n        # If this is the last chunk, break to avoid infinite loop\n        if end >= len(words):\n            break\n        start = end - overlap_words\n    \n    return chunks\n\n# Create chunked corpus for better embedding performance\nprint(\"🔄 Creating chunked corpus...\")\nchunked_data = []\n\nfor _, row in corpus_df.iterrows():\n    doc_chunks = chunk_text(row['text'], chunk_size_words=180, overlap_words=30)\n    \n    for chunk_idx, text_chunk in enumerate(doc_chunks):\n        chunked_data.append({\n            'doc_id': row['id'],\n            'chunk_id': f\"{row['id']}_chunk_{chunk_idx}\",\n            'title': row['title'],\n            'chunk_text': text_chunk\n        })\n\n# Convert to DataFrame for easy manipulation\nchunked_corpus = pd.DataFrame(chunked_data)\n\nprint(f\"📊 Created {len(chunked_corpus)} chunks from {len(corpus_df)} documents\")\nprint(f\"📏 Average chunk length: {chunked_corpus['chunk_text'].str.split().str.len().mean():.1f} words\")\n\n# Show chunk length distribution\nchunk_lengths = chunked_corpus['chunk_text'].str.split().str.len()\nprint(f\"📈 Chunk length distribution:\")\nprint(f\"  Min: {chunk_lengths.min()} words\")\nprint(f\"  Max: {chunk_lengths.max()} words\")\nprint(f\"  Median: {chunk_lengths.median():.1f} words\")\n\n# Show example of chunking\nsample_doc = corpus_df.iloc[0]\nsample_chunks = chunk_text(sample_doc['text'])\nprint(f\"\\n📋 Example chunking for '{sample_doc['title']}':\")\nprint(f\"Original text ({len(sample_doc['text'].split())} words):\")\nprint(f\"  {sample_doc['text'][:150]}...\")\nprint(f\"\\nChunks created: {len(sample_chunks)}\")\nfor i, chunk in enumerate(sample_chunks):\n    print(f\"  Chunk {i+1} ({len(chunk.split())} words): {chunk[:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:53.089853Z","iopub.execute_input":"2025-09-24T14:23:53.090232Z","iopub.status.idle":"2025-09-24T14:23:53.113468Z","shell.execute_reply.started":"2025-09-24T14:23:53.090188Z","shell.execute_reply":"2025-09-24T14:23:53.112236Z"}},"outputs":[{"name":"stdout","text":"🔄 Creating chunked corpus...\n📊 Created 30 chunks from 30 documents\n📏 Average chunk length: 52.0 words\n📈 Chunk length distribution:\n  Min: 45 words\n  Max: 64 words\n  Median: 51.0 words\n\n📋 Example chunking for 'Understanding Black Holes':\nOriginal text (64 words):\n  Black holes are regions of spacetime where gravity is so strong that nothing, including light, can escape once it crosses the event horizon. The event...\n\nChunks created: 1\n  Chunk 1 (64 words): Black holes are regions of spacetime where gravity is so strong that nothing, including light, can e...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Semantic embeddings using open-source sentence-transformers\nfrom sentence_transformers import SentenceTransformer\nimport os\n\n# Use a high-quality, lightweight open-source embedding model\n# all-MiniLM-L6-v2 provides good performance with reasonable speed\nmodel_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n# Alternative models (commented for reference):\n# model_name = \"BAAI/bge-small-en-v1.5\"  # Better quality, slightly larger\n# model_name = \"intfloat/e5-small-v2\"     # Good multilingual support\n\nprint(f\"🤖 Loading embedding model: {model_name}\")\nembedding_model = SentenceTransformer(model_name)\n\nprint(f\"📐 Model produces {embedding_model.get_sentence_embedding_dimension()}-dimensional vectors\")\n\n# Check if embeddings already exist to avoid recomputation\nembeddings_file = './data/embeddings.npz'\nchunks_file = './data/chunked_corpus.csv'\n\nif os.path.exists(embeddings_file) and os.path.exists(chunks_file):\n    print(\"📂 Loading pre-computed embeddings...\")\n    embeddings_data = np.load(embeddings_file)\n    chunk_embeddings = embeddings_data['embeddings']\n    chunked_corpus = pd.read_csv(chunks_file)\n    print(f\"✅ Loaded {len(chunk_embeddings)} embeddings from cache\")\nelse:\n    # Compute embeddings for all chunks with progress bar\n    print(f\"🔄 Computing embeddings for {len(chunked_corpus)} chunks...\")\n    \n    # Use tqdm for progress tracking during embedding computation\n    chunk_texts = chunked_corpus['chunk_text'].tolist()\n    \n    # sentence-transformers handles batching internally for efficiency\n    chunk_embeddings = embedding_model.encode(\n        chunk_texts, \n        batch_size=32,          # Process in batches for memory efficiency\n        show_progress_bar=True, # Show progress during computation\n        convert_to_numpy=True   # Return as numpy array\n    )\n    \n    # Save embeddings and chunks for future use\n    np.savez_compressed(embeddings_file, embeddings=chunk_embeddings)\n    chunked_corpus.to_csv(chunks_file, index=False)\n    print(f\"💾 Saved {len(chunk_embeddings)} embeddings to {embeddings_file}\")\n\n# Normalize embeddings for cosine similarity using dot product\n# This makes cosine similarity equivalent to dot product, which is faster\nfrom sklearn.preprocessing import normalize\nchunk_embeddings_normalized = normalize(chunk_embeddings, norm='l2')\n\nprint(f\"📊 Embedding matrix shape: {chunk_embeddings.shape}\")\nprint(f\"🎯 Embeddings normalized for cosine similarity\")\n\n# Choose between FAISS and sklearn based on availability\nif FAISS_AVAILABLE:\n    # Use FAISS for fast approximate nearest neighbor search\n    print(\"🚀 Using FAISS for fast similarity search\")\n    \n    # Create FAISS index for inner product (equivalent to cosine with normalized vectors)\n    embedding_dim = chunk_embeddings_normalized.shape[1]\n    faiss_index = faiss.IndexFlatIP(embedding_dim)  # Inner Product index\n    \n    # Add embeddings to index\n    faiss_index.add(chunk_embeddings_normalized.astype(np.float32))\n    \n    # Save FAISS index\n    faiss_index_file = './data/faiss.index'\n    faiss.write_index(faiss_index, faiss_index_file)\n    print(f\"💾 FAISS index saved to {faiss_index_file}\")\n    \n    search_backend = 'faiss'\n    \nelse:\n    # Use sklearn NearestNeighbors as fallback\n    print(\"📚 Using sklearn NearestNeighbors for similarity search\")\n    from sklearn.neighbors import NearestNeighbors\n    \n    # Create sklearn nearest neighbors index\n    nn_index = NearestNeighbors(\n        n_neighbors=20,      # Maximum neighbors to consider\n        metric='cosine',     # Use cosine similarity\n        algorithm='brute'    # Exact search for small datasets\n    )\n    nn_index.fit(chunk_embeddings)\n    \n    search_backend = 'sklearn'\n\ndef embed_query(query_text):\n    \"\"\"\n    Convert query text to embedding vector.\n    \n    Args:\n        query_text (str): The search query\n    \n    Returns:\n        np.ndarray: Query embedding vector\n    \"\"\"\n    query_embedding = embedding_model.encode([query_text], convert_to_numpy=True)\n    return normalize(query_embedding, norm='l2')[0]  # Normalize and return single vector\n\ndef semantic_search(query_text, top_k=10):\n    \"\"\"\n    Search for semantically similar chunks using embeddings.\n    \n    Args:\n        query_text (str): The search query\n        top_k (int): Number of top results to return\n    \n    Returns:\n        list: Tuples of (chunk_index, similarity_score, chunk_info)\n    \"\"\"\n    # Get query embedding\n    query_embedding = embed_query(query_text)\n    \n    if search_backend == 'faiss':\n        # Use FAISS for fast search\n        scores, indices = faiss_index.search(\n            query_embedding.reshape(1, -1).astype(np.float32), \n            top_k\n        )\n        \n        results = []\n        for i, (idx, score) in enumerate(zip(indices[0], scores[0])):\n            chunk_info = {\n                'chunk_id': chunked_corpus.iloc[idx]['chunk_id'],\n                'doc_id': chunked_corpus.iloc[idx]['doc_id'],\n                'title': chunked_corpus.iloc[idx]['title'],\n                'chunk_text': chunked_corpus.iloc[idx]['chunk_text']\n            }\n            results.append((idx, score, chunk_info))\n    \n    else:\n        # Use sklearn for search\n        distances, indices = nn_index.kneighbors(\n            query_embedding.reshape(1, -1), \n            n_neighbors=min(top_k, len(chunked_corpus))\n        )\n        \n        results = []\n        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):\n            # Convert cosine distance to similarity (1 - distance)\n            similarity = 1 - distance\n            chunk_info = {\n                'chunk_id': chunked_corpus.iloc[idx]['chunk_id'],\n                'doc_id': chunked_corpus.iloc[idx]['doc_id'],\n                'title': chunked_corpus.iloc[idx]['title'],\n                'chunk_text': chunked_corpus.iloc[idx]['chunk_text']\n            }\n            results.append((idx, similarity, chunk_info))\n    \n    return results\n\n# Test semantic search\ntest_queries = [\n    \"stellar collapse and gravitational effects\",\n    \"modifying function behavior in programming\",\n    \"heart health and physical activity\"\n]\n\nprint(\"\\n🔍 Testing semantic search:\")\nfor query in test_queries:\n    print(f\"\\n📋 Query: '{query}'\")\n    results = semantic_search(query, top_k=5)\n    \n    print(\"Top 5 semantic matches:\")\n    for rank, (idx, score, chunk_info) in enumerate(results, 1):\n        print(f\"  {rank}. [{chunk_info['doc_id']}] {chunk_info['title']} (similarity: {score:.3f})\")\n        snippet = chunk_info['chunk_text'][:100] + '...'\n        print(f\"      {snippet}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:23:53.114572Z","iopub.execute_input":"2025-09-24T14:23:53.114863Z","iopub.status.idle":"2025-09-24T14:24:07.820433Z","shell.execute_reply.started":"2025-09-24T14:23:53.114830Z","shell.execute_reply":"2025-09-24T14:24:07.819434Z"}},"outputs":[{"name":"stdout","text":"🤖 Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7dffbcbd884d37b4f5313db170ec84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d031a80c1b694acd8314e735d6a454a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee862b929f58476ab900da96af0d1d2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa537635e29411d902fbd5589ba622b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a417234129e5491fad88a7620c105673"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a2b38adb16c418c9344fd97a4adfb5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e21c51caa03242cbbe0eafb69f1433a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be8ca7aebf746c1a3f403f066bc55e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6060d322d6e4484a0735b58b9a3bda9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be06cb167a540658c6f3735de7a32aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebcdd2aab3a44d1a76ecbb936ddecfb"}},"metadata":{}},{"name":"stdout","text":"📐 Model produces 384-dimensional vectors\n🔄 Computing embeddings for 30 chunks...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606229e2a1c848fe8900be675c411a7b"}},"metadata":{}},{"name":"stdout","text":"💾 Saved 30 embeddings to ./data/embeddings.npz\n📊 Embedding matrix shape: (30, 384)\n🎯 Embeddings normalized for cosine similarity\n🚀 Using FAISS for fast similarity search\n💾 FAISS index saved to ./data/faiss.index\n\n🔍 Testing semantic search:\n\n📋 Query: 'stellar collapse and gravitational effects'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47492a2ec0174c12b31016f983aff191"}},"metadata":{}},{"name":"stdout","text":"Top 5 semantic matches:\n  1. [ast_002] The Life Cycle of Stars (similarity: 0.420)\n      Stars are born from clouds of gas and dust called nebulae. Through gravitational collapse, the core ...\n  2. [ast_001] Understanding Black Holes (similarity: 0.377)\n      Black holes are regions of spacetime where gravity is so strong that nothing, including light, can e...\n  3. [ast_003] Solar System Formation (similarity: 0.342)\n      The solar system formed approximately 4.6 billion years ago from the gravitational collapse of a mol...\n  4. [ast_005] Dark Matter and Dark Energy (similarity: 0.295)\n      Dark matter makes up approximately 27% of the universe but doesn't interact electromagnetically, mak...\n  5. [ast_004] Exoplanet Detection Methods (similarity: 0.236)\n      Astronomers use several methods to detect exoplanets. The transit method observes the dimming of a s...\n\n📋 Query: 'modifying function behavior in programming'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d0c2a09d1ee443ca43d81975c7c660c"}},"metadata":{}},{"name":"stdout","text":"Top 5 semantic matches:\n  1. [py_001] Object-Oriented Programming Concepts (similarity: 0.313)\n      Object-oriented programming organizes code around objects rather than functions. Classes serve as bl...\n  2. [py_003] Asynchronous Programming Patterns (similarity: 0.270)\n      Asynchronous programming enables concurrent execution without blocking operations. The async/await s...\n  3. [py_002] Efficient Data Processing with Pandas (similarity: 0.211)\n      Pandas provides powerful data structures and operations for manipulating structured data. DataFrames...\n  4. [cook_005] Baking Science and Techniques (similarity: 0.163)\n      Baking relies on precise chemical reactions between ingredients. Gluten development in flour provide...\n  5. [py_004] Machine Learning Pipeline Design (similarity: 0.139)\n      ML pipelines automate the workflow from raw data to trained models. Data preprocessing includes clea...\n\n📋 Query: 'heart health and physical activity'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c82f4768490f48709f433e538b5dfd5b"}},"metadata":{}},{"name":"stdout","text":"Top 5 semantic matches:\n  1. [heal_002] Cardiovascular Health (similarity: 0.591)\n      The cardiovascular system pumps blood through a network of vessels, delivering oxygen and nutrients ...\n  2. [sport_001] Athletic Performance Optimization (similarity: 0.343)\n      Peak athletic performance requires balancing training stress, recovery, and adaptation. Periodizatio...\n  3. [sport_005] Endurance Training Methodologies (similarity: 0.339)\n      Endurance training improves the body's ability to sustain prolonged physical activity. Training zone...\n  4. [sport_003] Injury Prevention Strategies (similarity: 0.320)\n      Injury prevention combines proper warm-up, strength training, and biomechanical awareness. Dynamic w...\n  5. [heal_003] Mental Health and Wellness (similarity: 0.275)\n      Mental health encompasses emotional, psychological, and social well-being, affecting thoughts, feeli...\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Hybrid Retrieval: Best of Both Worlds\n\n**Hybrid retrieval** combines lexical (BM25) and semantic (embeddings) approaches to leverage their complementary strengths:\n\n### Lexical Strengths\n- Exact term matching for technical terms and proper names\n- Fast computation and interpretable results\n- Robust to domain shifts\n\n### Semantic Strengths\n- Conceptual matching beyond exact words\n- Better handling of synonyms and paraphrases\n- Context-aware understanding\n\n### Hybrid Strategy\n1. **Union approach**: Get candidates from both methods\n2. **Score normalization**: Make scores comparable across methods\n3. **Rank fusion**: Combine rankings intelligently\n\n### Score Normalization\nDifferent retrieval methods produce scores on different scales. Min-max normalization maps all scores to [0,1] range:\n```\nnormalized_score = (score - min_score) / (max_score - min_score)\n```\n\nThis ensures fair combination across methods, preventing one method from dominating due to larger score magnitudes.\n\nHybrid retrieval typically improves both **recall** (finding relevant documents) and **robustness** (handling diverse query types).","metadata":{}},{"cell_type":"code","source":"# Hybrid retrieval combining lexical and semantic approaches\nimport pandas as pd\n\ndef normalize_scores(scores):\n    \"\"\"Normalize scores to [0, 1] range using min-max scaling.\"\"\"\n    if not scores:\n        return []\n    \n    min_score = min(scores)\n    max_score = max(scores)\n    \n    # Handle case where all scores are the same\n    if min_score == max_score:\n        return [1.0] * len(scores)\n    \n    # Apply min-max normalization\n    normalized = [(score - min_score) / (max_score - min_score) for score in scores]\n    return normalized\n\ndef hybrid_retrieve(query_text, top_k_lex=15, top_k_sem=15):\n    \"\"\"\n    Combine lexical (BM25) and semantic retrieval results.\n    Uses union of candidates and normalizes scores for fair comparison.\n    \n    Args:\n        query_text (str): The search query\n        top_k_lex (int): Number of lexical results to retrieve\n        top_k_sem (int): Number of semantic results to retrieve\n    \n    Returns:\n        pd.DataFrame: Combined results with normalized scores\n    \"\"\"\n    # Get BM25 results on original documents (not chunks)\n    bm25_results = query_bm25(query_text, top_k=top_k_lex)\n    \n    # Get semantic results on chunks\n    semantic_results = semantic_search(query_text, top_k=top_k_sem)\n    \n    # Create unified candidate list\n    candidates = {}\n    \n    # Process BM25 results\n    bm25_scores = [score for _, score, _ in bm25_results]\n    normalized_bm25_scores = normalize_scores(bm25_scores)\n    \n    for (doc_idx, score, doc_info), norm_score in zip(bm25_results, normalized_bm25_scores):\n        doc_id = doc_info['id']\n        if doc_id not in candidates:\n            candidates[doc_id] = {\n                'doc_id': doc_id,\n                'title': doc_info['title'],\n                'text': doc_info['text'],\n                'bm25_score': score,\n                'bm25_rank': len(candidates) + 1,\n                'bm25_normalized': norm_score,\n                'semantic_score': 0,\n                'semantic_rank': None,\n                'semantic_normalized': 0\n            }\n    \n    # Process semantic results\n    semantic_scores = [score for _, score, _ in semantic_results]\n    normalized_semantic_scores = normalize_scores(semantic_scores)\n    \n    for (chunk_idx, score, chunk_info), norm_score in zip(semantic_results, normalized_semantic_scores):\n        doc_id = chunk_info['doc_id']\n        \n        if doc_id not in candidates:\n            # Find original document info for new semantic candidates\n            # Add error handling for missing documents\n            matching_docs = corpus_df[corpus_df['id'] == doc_id]\n            if matching_docs.empty:\n                print(f\"⚠️ Warning: Document {doc_id} from semantic search not found in corpus_df\")\n                print(f\"   Available corpus IDs: {corpus_df['id'].head().tolist()}\")\n                print(f\"   Chunk info: {chunk_info}\")\n                continue  # Skip this document\n                \n            orig_doc = matching_docs.iloc[0]\n            candidates[doc_id] = {\n                'doc_id': doc_id,\n                'title': orig_doc['title'],\n                'text': orig_doc['text'],\n                'bm25_score': 0,\n                'bm25_rank': None,\n                'bm25_normalized': 0,\n                'semantic_score': score,\n                'semantic_rank': len([r for r in semantic_results if r[2]['doc_id'] == doc_id]) + 1,\n                'semantic_normalized': norm_score\n            }\n        else:\n            # Update existing candidate with semantic info\n            # Take best semantic score if multiple chunks from same document\n            if score > candidates[doc_id]['semantic_score']:\n                candidates[doc_id]['semantic_score'] = score\n                candidates[doc_id]['semantic_normalized'] = norm_score\n                candidates[doc_id]['semantic_rank'] = len([r for r in semantic_results if r[2]['doc_id'] == doc_id]) + 1\n    \n    # Convert to DataFrame for easy manipulation\n    hybrid_results = pd.DataFrame.from_dict(candidates, orient='index')\n    \n    return hybrid_results\n\n# Test hybrid retrieval\ntest_query = \"black hole formation from stellar collapse\"\n\nprint(f\"🔍 Testing hybrid retrieval for: '{test_query}'\")\nhybrid_df = hybrid_retrieve(test_query, top_k_lex=10, top_k_sem=10)\n\nprint(f\"\\n📊 Found {len(hybrid_df)} unique documents from hybrid approach\")\n\n# Show method comparison\nbm25_only = hybrid_df[hybrid_df['bm25_rank'].notna()].shape[0]\nsemantic_only = hybrid_df[hybrid_df['semantic_rank'].notna()].shape[0]\nboth_methods = hybrid_df[(hybrid_df['bm25_rank'].notna()) & (hybrid_df['semantic_rank'].notna())].shape[0]\n\nprint(f\"\\n📈 Method coverage:\")\nprint(f\"  BM25 found: {bm25_only} documents\")\nprint(f\"  Semantic found: {semantic_only} documents\")\nprint(f\"  Both methods found: {both_methods} documents\")\nprint(f\"  Union: {len(hybrid_df)} documents\")\n\n# Display top hybrid results using proper DataFrame display\nprint(f\"\\n📋 Top 10 candidates for rank fusion:\")\n\n# Create a clean display DataFrame with selected columns\ndisplay_df = hybrid_df[['doc_id', 'title', 'bm25_normalized', 'semantic_normalized', 'bm25_rank', 'semantic_rank']].head(10).copy()\n\n# Format numeric columns for better display\ndisplay_df['bm25_normalized'] = display_df['bm25_normalized'].round(3)\ndisplay_df['semantic_normalized'] = display_df['semantic_normalized'].round(3)\n\n# Truncate titles for better display\ndisplay_df['title'] = display_df['title'].str[:50] + '...'\n\n# Rename columns for cleaner display\ndisplay_df.columns = ['Doc ID', 'Title', 'BM25 Score', 'Semantic Score', 'BM25 Rank', 'Semantic Rank']\n\n# Display the formatted DataFrame\ndisplay(display_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:07.821560Z","iopub.execute_input":"2025-09-24T14:24:07.822043Z","iopub.status.idle":"2025-09-24T14:24:07.909204Z","shell.execute_reply.started":"2025-09-24T14:24:07.822011Z","shell.execute_reply":"2025-09-24T14:24:07.908389Z"}},"outputs":[{"name":"stdout","text":"🔍 Testing hybrid retrieval for: 'black hole formation from stellar collapse'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"048515845f5c44468543c8908a8769e6"}},"metadata":{}},{"name":"stdout","text":"\n📊 Found 14 unique documents from hybrid approach\n\n📈 Method coverage:\n  BM25 found: 10 documents\n  Semantic found: 10 documents\n  Both methods found: 6 documents\n  Union: 14 documents\n\n📋 Top 10 candidates for rank fusion:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            Doc ID                                      Title  BM25 Score  \\\nast_001    ast_001               Understanding Black Holes...       1.000   \nast_005    ast_005             Dark Matter and Dark Energy...       0.690   \nast_002    ast_002                 The Life Cycle of Stars...       0.532   \nast_003    ast_003                  Solar System Formation...       0.511   \nhist_001  hist_001               The Industrial Revolution...       0.279   \npy_004      py_004        Machine Learning Pipeline Design...       0.205   \nhist_003  hist_003                  The Renaissance Period...       0.186   \nast_004    ast_004             Exoplanet Detection Methods...       0.178   \ncook_001  cook_001                  Essential Knife Skills...       0.000   \ncook_002  cook_002  Understanding Heat and Cooking Methods...       0.000   \n\n          Semantic Score  BM25 Rank  Semantic Rank  \nast_001            1.000        1.0            2.0  \nast_005            0.333        2.0            2.0  \nast_002            0.817        3.0            2.0  \nast_003            0.777        4.0            2.0  \nhist_001           0.000        5.0            NaN  \npy_004             0.000        6.0            NaN  \nhist_003           0.000        7.0            NaN  \nast_004            0.197        8.0            2.0  \ncook_001           0.016        9.0            2.0  \ncook_002           0.000       10.0            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Doc ID</th>\n      <th>Title</th>\n      <th>BM25 Score</th>\n      <th>Semantic Score</th>\n      <th>BM25 Rank</th>\n      <th>Semantic Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ast_001</th>\n      <td>ast_001</td>\n      <td>Understanding Black Holes...</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>ast_005</th>\n      <td>ast_005</td>\n      <td>Dark Matter and Dark Energy...</td>\n      <td>0.690</td>\n      <td>0.333</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>ast_002</th>\n      <td>ast_002</td>\n      <td>The Life Cycle of Stars...</td>\n      <td>0.532</td>\n      <td>0.817</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>ast_003</th>\n      <td>ast_003</td>\n      <td>Solar System Formation...</td>\n      <td>0.511</td>\n      <td>0.777</td>\n      <td>4.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>hist_001</th>\n      <td>hist_001</td>\n      <td>The Industrial Revolution...</td>\n      <td>0.279</td>\n      <td>0.000</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>py_004</th>\n      <td>py_004</td>\n      <td>Machine Learning Pipeline Design...</td>\n      <td>0.205</td>\n      <td>0.000</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>hist_003</th>\n      <td>hist_003</td>\n      <td>The Renaissance Period...</td>\n      <td>0.186</td>\n      <td>0.000</td>\n      <td>7.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ast_004</th>\n      <td>ast_004</td>\n      <td>Exoplanet Detection Methods...</td>\n      <td>0.178</td>\n      <td>0.197</td>\n      <td>8.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>cook_001</th>\n      <td>cook_001</td>\n      <td>Essential Knife Skills...</td>\n      <td>0.000</td>\n      <td>0.016</td>\n      <td>9.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>cook_002</th>\n      <td>cook_002</td>\n      <td>Understanding Heat and Cooking Methods...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>10.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Rank Fusion: Reciprocal Rank Fusion (RRF)\n\n**Reciprocal Rank Fusion (RRF)** is a simple yet effective method for combining rankings from multiple retrieval systems. It's particularly robust because it relies on ranks rather than raw scores.\n\n### RRF Formula\nFor each document, RRF computes:\n```\nRRF_score = Σ (1 / (k + rank_i))\n```\nwhere:\n- `rank_i` is the document's rank in system i\n- `k` is a constant (typically 60) that controls the contribution curve\n- The sum is over all systems that retrieved the document\n\n### Why RRF Works Well\n1. **Rank-based**: Avoids issues with different score scales\n2. **Robust**: Less sensitive to outliers than score-based fusion\n3. **Simple**: No parameter tuning beyond choosing k\n4. **Proven**: Works well across different retrieval types\n\n### Parameter k\n- **k=60** (default): Balanced contribution from all ranks\n- **Lower k**: Top ranks dominate more\n- **Higher k**: More uniform contribution across ranks\n\nDocuments appearing in multiple systems get higher RRF scores, while high-ranking documents in any single system also score well.","metadata":{}},{"cell_type":"code","source":"# Reciprocal Rank Fusion (RRF) implementation\n# RRF is a robust method for combining rankings from different retrieval systems\n\ndef rrf_fuse(rankings, k=60):\n    \"\"\"\n    Apply Reciprocal Rank Fusion to combine multiple ranking methods.\n    \n    Args:\n        rankings (dict): Dictionary mapping method names to lists of (doc_id, rank) tuples\n        k (int): RRF parameter controlling rank contribution curve (default: 60)\n    \n    Returns:\n        list: Tuples of (doc_id, rrf_score, method_details)\n    \"\"\"\n    # Collect all unique document IDs\n    all_doc_ids = set()\n    for method_rankings in rankings.values():\n        all_doc_ids.update(doc_id for doc_id, _ in method_rankings)\n    \n    # Calculate RRF scores for each document\n    rrf_scores = {}\n    method_details = {}\n    \n    for doc_id in all_doc_ids:\n        total_score = 0\n        doc_method_info = {}\n        \n        # Sum reciprocal ranks across all methods that retrieved this document\n        for method_name, method_rankings in rankings.items():\n            # Find this document's rank in the current method\n            doc_rank = None\n            for d_id, rank in method_rankings:\n                if d_id == doc_id:\n                    doc_rank = rank\n                    break\n            \n            if doc_rank is not None:\n                # Calculate reciprocal rank contribution\n                contribution = 1 / (k + doc_rank)\n                total_score += contribution\n                doc_method_info[method_name] = {\n                    'rank': doc_rank,\n                    'contribution': contribution\n                }\n            else:\n                doc_method_info[method_name] = {\n                    'rank': None,\n                    'contribution': 0\n                }\n        \n        rrf_scores[doc_id] = total_score\n        method_details[doc_id] = doc_method_info\n    \n    # Sort by RRF score (highest first)\n    sorted_results = sorted(\n        [(doc_id, score, method_details[doc_id]) \n         for doc_id, score in rrf_scores.items()],\n        key=lambda x: x[1],\n        reverse=True\n    )\n    \n    return sorted_results\n\ndef apply_rrf_to_hybrid(hybrid_df, k=60):\n    \"\"\"\n    Apply RRF to hybrid retrieval results.\n    \n    Args:\n        hybrid_df (pd.DataFrame): Hybrid retrieval results\n        k (int): RRF parameter\n    \n    Returns:\n        list: RRF fused results\n    \"\"\"\n    # Prepare rankings for RRF\n    rankings = {}\n    \n    # BM25 rankings (only for documents that have BM25 results)\n    bm25_docs = hybrid_df[hybrid_df['bm25_rank'].notna()]\n    if len(bm25_docs) > 0:\n        bm25_rankings = [(row['doc_id'], row['bm25_rank']) \n                        for _, row in bm25_docs.iterrows()]\n        rankings['BM25'] = bm25_rankings\n    \n    # Semantic rankings (only for documents that have semantic results)\n    semantic_docs = hybrid_df[hybrid_df['semantic_rank'].notna()]\n    if len(semantic_docs) > 0:\n        semantic_rankings = [(row['doc_id'], row['semantic_rank']) \n                           for _, row in semantic_docs.iterrows()]\n        rankings['Semantic'] = semantic_rankings\n    \n    # Apply RRF\n    rrf_results = rrf_fuse(rankings, k=k)\n    \n    # Enrich results with document information\n    enriched_results = []\n    for doc_id, rrf_score, method_info in rrf_results:\n        doc_row = hybrid_df[hybrid_df['doc_id'] == doc_id].iloc[0]\n        enriched_results.append({\n            'doc_id': doc_id,\n            'title': doc_row['title'],\n            'text': doc_row['text'],\n            'rrf_score': rrf_score,\n            'method_info': method_info,\n            'bm25_rank': doc_row['bm25_rank'] if pd.notna(doc_row['bm25_rank']) else None,\n            'semantic_rank': doc_row['semantic_rank'] if pd.notna(doc_row['semantic_rank']) else None\n        })\n    \n    return enriched_results\n\n# Test RRF on our hybrid results\ntest_query = \"black hole formation from stellar collapse\"\nprint(f\"🔍 Applying RRF to query: '{test_query}'\")\n\n# Get hybrid results\nhybrid_df = hybrid_retrieve(test_query, top_k_lex=10, top_k_sem=10)\n\n# Apply RRF\nrrf_results = apply_rrf_to_hybrid(hybrid_df, k=60)\n\nprint(f\"\\n📊 RRF Results (k=60):\")\n\n# Create DataFrame for better display of RRF results\nrrf_display_data = []\nfor rank, result in enumerate(rrf_results[:10], 1):\n    rrf_display_data.append({\n        'Rank': rank,\n        'Doc ID': result['doc_id'],\n        'Title': result['title'][:40] + '...' if len(result['title']) > 40 else result['title'],\n        'RRF Score': round(result['rrf_score'], 4),\n        'BM25 Rank': result['bm25_rank'] if result['bm25_rank'] is not None else None,\n        'Semantic Rank': result['semantic_rank'] if result['semantic_rank'] is not None else None\n    })\n\nrrf_df = pd.DataFrame(rrf_display_data)\nprint(\"\\nTop 10 documents after RRF fusion:\")\ndisplay(rrf_df)\n\n# Analyze method contributions\nprint(f\"\\n📈 Method contribution analysis for top 5 results:\")\nfor i, result in enumerate(rrf_results[:5], 1):\n    print(f\"\\n{i}. [{result['doc_id']}] {result['title']}\")\n    print(f\"   Total RRF score: {result['rrf_score']:.4f}\")\n    \n    for method, info in result['method_info'].items():\n        if info['rank'] is not None:\n            print(f\"   {method}: rank {info['rank']:.0f} → contribution {info['contribution']:.4f}\")\n        else:\n            print(f\"   {method}: not found → contribution 0.0000\")\n\n# Test different k values to show effect\nprint(f\"\\n🔬 Effect of different k values on top result:\")\n\nk_comparison_data = []\nfor k_val in [10, 30, 60, 100]:\n    rrf_k = apply_rrf_to_hybrid(hybrid_df, k=k_val)\n    top_result = rrf_k[0]\n    k_comparison_data.append({\n        'k Value': k_val,\n        'Top Doc ID': top_result['doc_id'],\n        'Title': top_result['title'][:50] + '...' if len(top_result['title']) > 50 else top_result['title'],\n        'RRF Score': round(top_result['rrf_score'], 4)\n    })\n\nk_comparison_df = pd.DataFrame(k_comparison_data)\ndisplay(k_comparison_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:07.910584Z","iopub.execute_input":"2025-09-24T14:24:07.910876Z","iopub.status.idle":"2025-09-24T14:24:08.116471Z","shell.execute_reply.started":"2025-09-24T14:24:07.910855Z","shell.execute_reply":"2025-09-24T14:24:08.115649Z"}},"outputs":[{"name":"stdout","text":"🔍 Applying RRF to query: 'black hole formation from stellar collapse'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cbd1471ee245258451ad4980653c6d"}},"metadata":{}},{"name":"stdout","text":"\n📊 RRF Results (k=60):\n\nTop 10 documents after RRF fusion:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Rank    Doc ID                            Title  RRF Score  BM25 Rank  \\\n0     1   ast_001        Understanding Black Holes     0.0325        1.0   \n1     2   ast_005      Dark Matter and Dark Energy     0.0323        2.0   \n2     3   ast_002          The Life Cycle of Stars     0.0320        3.0   \n3     4   ast_003           Solar System Formation     0.0318        4.0   \n4     5   ast_004      Exoplanet Detection Methods     0.0308        8.0   \n5     6  cook_001           Essential Knife Skills     0.0306        9.0   \n6     7  hist_004      World War Impact on Society     0.0161        NaN   \n7     8  hist_005                 The Cold War Era     0.0161        NaN   \n8     9  hist_002  Ancient Civilizations and Trade     0.0161        NaN   \n9    10  cook_004        Sauce Making Fundamentals     0.0161        NaN   \n\n   Semantic Rank  \n0            2.0  \n1            2.0  \n2            2.0  \n3            2.0  \n4            2.0  \n5            2.0  \n6            2.0  \n7            2.0  \n8            2.0  \n9            2.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Doc ID</th>\n      <th>Title</th>\n      <th>RRF Score</th>\n      <th>BM25 Rank</th>\n      <th>Semantic Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.0325</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>ast_005</td>\n      <td>Dark Matter and Dark Energy</td>\n      <td>0.0323</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>ast_002</td>\n      <td>The Life Cycle of Stars</td>\n      <td>0.0320</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ast_003</td>\n      <td>Solar System Formation</td>\n      <td>0.0318</td>\n      <td>4.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>ast_004</td>\n      <td>Exoplanet Detection Methods</td>\n      <td>0.0308</td>\n      <td>8.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>cook_001</td>\n      <td>Essential Knife Skills</td>\n      <td>0.0306</td>\n      <td>9.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>hist_004</td>\n      <td>World War Impact on Society</td>\n      <td>0.0161</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>hist_005</td>\n      <td>The Cold War Era</td>\n      <td>0.0161</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>hist_002</td>\n      <td>Ancient Civilizations and Trade</td>\n      <td>0.0161</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>cook_004</td>\n      <td>Sauce Making Fundamentals</td>\n      <td>0.0161</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n📈 Method contribution analysis for top 5 results:\n\n1. [ast_001] Understanding Black Holes\n   Total RRF score: 0.0325\n   BM25: rank 1 → contribution 0.0164\n   Semantic: rank 2 → contribution 0.0161\n\n2. [ast_005] Dark Matter and Dark Energy\n   Total RRF score: 0.0323\n   BM25: rank 2 → contribution 0.0161\n   Semantic: rank 2 → contribution 0.0161\n\n3. [ast_002] The Life Cycle of Stars\n   Total RRF score: 0.0320\n   BM25: rank 3 → contribution 0.0159\n   Semantic: rank 2 → contribution 0.0161\n\n4. [ast_003] Solar System Formation\n   Total RRF score: 0.0318\n   BM25: rank 4 → contribution 0.0156\n   Semantic: rank 2 → contribution 0.0161\n\n5. [ast_004] Exoplanet Detection Methods\n   Total RRF score: 0.0308\n   BM25: rank 8 → contribution 0.0147\n   Semantic: rank 2 → contribution 0.0161\n\n🔬 Effect of different k values on top result:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   k Value Top Doc ID                      Title  RRF Score\n0       10    ast_001  Understanding Black Holes     0.1742\n1       30    ast_001  Understanding Black Holes     0.0635\n2       60    ast_001  Understanding Black Holes     0.0325\n3      100    ast_001  Understanding Black Holes     0.0197","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>k Value</th>\n      <th>Top Doc ID</th>\n      <th>Title</th>\n      <th>RRF Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.1742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.0635</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.0325</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.0197</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Re-ranking with Cross-Encoders\n\n**Cross-encoders** are transformer models that score (query, passage) pairs directly, providing more accurate relevance estimates than individual embeddings. They're the \"second stage\" in a two-stage retrieval pipeline.\n\n### How Cross-Encoders Work\nUnlike bi-encoders (like sentence-transformers) that encode query and document separately, cross-encoders:\n1. Concatenate query and passage as input: `[CLS] query [SEP] passage [SEP]`\n2. Use full attention across query-passage pairs\n3. Output a single relevance score\n\n### Advantages\n- **Higher accuracy**: Full attention between query and passage\n- **Better ranking**: Specifically trained for relevance scoring\n- **Fine-grained scoring**: Can distinguish subtle relevance differences\n\n### Trade-offs\n- **Computational cost**: Must process each (query, candidate) pair\n- **Latency**: Slower than embedding-based similarity\n- **Scale limitations**: Practical only for re-ranking small candidate sets\n\n### Best Practice\nUse cross-encoders to re-rank the top-N (typically 10-50) candidates from faster retrieval methods. This gives you both speed and accuracy.","metadata":{}},{"cell_type":"code","source":"# Re-ranking with open-source cross-encoder models\n# Cross-encoders provide more accurate relevance scoring for final ranking\nimport time\n\n# Load a lightweight cross-encoder model\n# ms-marco-MiniLM is trained on Microsoft's passage ranking dataset\ncross_encoder_model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n# Alternative models (commented for reference):\n# cross_encoder_model_name = \"BAAI/bge-reranker-base\"          # Higher quality, larger\n# cross_encoder_model_name = \"cross-encoder/ms-marco-TinyBERT-L-2-v2\"  # Faster, smaller\n\nprint(f\"🤖 Loading cross-encoder: {cross_encoder_model_name}\")\ncross_encoder = CrossEncoder(cross_encoder_model_name)\nprint(\"✅ Cross-encoder loaded successfully\")\n\ndef rerank_with_cross_encoder(query_text, candidates, top_k=10):\n    \"\"\"\n    Re-rank candidates using a cross-encoder model.\n    \n    Args:\n        query_text (str): The search query\n        candidates (list): List of candidate documents with text\n        top_k (int): Number of top results to return after re-ranking\n    \n    Returns:\n        list: Re-ranked candidates with cross-encoder scores\n    \"\"\"\n    if not candidates:\n        return []\n    \n    start_time = time.time()\n    \n    # Prepare (query, passage) pairs for the cross-encoder\n    # Use document title + text for better context\n    query_passage_pairs = []\n    for candidate in candidates:\n        # Combine title and text for richer passage representation\n        passage_text = f\"{candidate['title']}. {candidate['text']}\"\n        query_passage_pairs.append([query_text, passage_text])\n    \n    # Get relevance scores from cross-encoder\n    # Scores are logits that can be interpreted as relevance strength\n    print(f\"🔄 Computing cross-encoder scores for {len(query_passage_pairs)} candidates...\")\n    relevance_scores = cross_encoder.predict(query_passage_pairs)\n    \n    # Combine candidates with their cross-encoder scores\n    scored_candidates = []\n    for candidate, ce_score in zip(candidates, relevance_scores):\n        scored_candidate = candidate.copy()\n        scored_candidate['cross_encoder_score'] = float(ce_score)\n        scored_candidates.append(scored_candidate)\n    \n    # Sort by cross-encoder score (highest first)\n    reranked = sorted(scored_candidates, \n                     key=lambda x: x['cross_encoder_score'], \n                     reverse=True)\n    \n    elapsed_time = time.time() - start_time\n    print(f\"⏱️  Cross-encoder re-ranking completed in {elapsed_time:.2f} seconds\")\n    \n    return reranked[:top_k]\n\n# Test cross-encoder re-ranking on RRF results\ntest_query = \"black hole formation from stellar collapse\"\nprint(f\"\\n🔍 Testing cross-encoder re-ranking for: '{test_query}'\")\n\n# Get RRF results as candidates for re-ranking\nhybrid_df = hybrid_retrieve(test_query, top_k_lex=15, top_k_sem=15)\nrrf_candidates = apply_rrf_to_hybrid(hybrid_df, k=60)\n\n# Take top 20 RRF candidates for re-ranking (manageable size for cross-encoder)\ncandidates_for_reranking = rrf_candidates[:20]\n\nprint(f\"\\n📊 Re-ranking top {len(candidates_for_reranking)} RRF candidates\")\n\n# Apply cross-encoder re-ranking\nreranked_results = rerank_with_cross_encoder(\n    test_query, \n    candidates_for_reranking, \n    top_k=10\n)\n\n# Display comparison: RRF order vs Cross-encoder order\nprint(f\"\\n📈 Comparison: RRF vs Cross-Encoder ranking\")\n\nprint(\"\\nRRF Ranking (before re-ranking) - Top 5:\")\nrrf_display_data = []\nfor i, candidate in enumerate(candidates_for_reranking[:5], 1):\n    rrf_display_data.append({\n        'Rank': i,\n        'Doc ID': candidate['doc_id'],\n        'Title': candidate['title'][:40] + '...' if len(candidate['title']) > 40 else candidate['title'],\n        'RRF Score': round(candidate['rrf_score'], 4)\n    })\n\nrrf_comparison_df = pd.DataFrame(rrf_display_data)\ndisplay(rrf_comparison_df)\n\nprint(\"\\nCross-Encoder Ranking (after re-ranking) - Top 5:\")\nce_display_data = []\nfor i, result in enumerate(reranked_results[:5], 1):\n    ce_display_data.append({\n        'Rank': i,\n        'Doc ID': result['doc_id'],\n        'Title': result['title'][:40] + '...' if len(result['title']) > 40 else result['title'],\n        'CE Score': round(result['cross_encoder_score'], 4),\n        'RRF Score': round(result['rrf_score'], 4)\n    })\n\nce_comparison_df = pd.DataFrame(ce_display_data)\ndisplay(ce_comparison_df)\n\n# Show detailed results with snippets\nprint(f\"\\n📋 Top 5 results with snippets:\")\nfor i, result in enumerate(reranked_results[:5], 1):\n    print(f\"\\n{i}. [{result['doc_id']}] {result['title']}\")\n    print(f\"   Cross-encoder score: {result['cross_encoder_score']:.4f}\")\n    print(f\"   Original RRF score: {result['rrf_score']:.4f}\")\n    \n    # Show first 200 characters as snippet\n    snippet = result['text'][:200] + '...' if len(result['text']) > 200 else result['text']\n    print(f\"   Snippet: {snippet}\")\n\n# Analyze ranking changes\nprint(f\"\\n🔄 Ranking changes analysis:\")\nrank_changes = []\nfor i, reranked_doc in enumerate(reranked_results[:10], 1):\n    # Find original RRF position\n    original_rank = None\n    for j, original_doc in enumerate(candidates_for_reranking, 1):\n        if original_doc['doc_id'] == reranked_doc['doc_id']:\n            original_rank = j\n            break\n    \n    change = original_rank - i if original_rank else \"New\"\n    rank_changes.append({\n        'Doc ID': reranked_doc['doc_id'],\n        'Original RRF Rank': original_rank,\n        'New CE Rank': i,\n        'Position Change': f\"+{change}\" if isinstance(change, int) and change > 0 else str(change),\n        'Direction': '↑' if isinstance(change, int) and change > 0 else ('↓' if isinstance(change, int) and change < 0 else '→')\n    })\n\nrank_changes_df = pd.DataFrame(rank_changes)\ndisplay(rank_changes_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:08.117392Z","iopub.execute_input":"2025-09-24T14:24:08.117642Z","iopub.status.idle":"2025-09-24T14:24:15.529532Z","shell.execute_reply.started":"2025-09-24T14:24:08.117615Z","shell.execute_reply":"2025-09-24T14:24:15.528642Z"}},"outputs":[{"name":"stdout","text":"🤖 Loading cross-encoder: cross-encoder/ms-marco-MiniLM-L-6-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba8d8ef5fef48b38e88fa5013918a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d44d48df0b45b7a5ddfdf398001027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81906f77aff54fe2b48ea6cc2007f3d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb6bdd0d33ed4f10948b54f8f7fce20c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"821548c2667f4fe1b42d2a35183fd39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60eeacdd86b545d19ed8f1d88aa4fa1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39811975c72d48099d541c8c4cb48d52"}},"metadata":{}},{"name":"stdout","text":"✅ Cross-encoder loaded successfully\n\n🔍 Testing cross-encoder re-ranking for: 'black hole formation from stellar collapse'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed127fef565b4bfa9001e592613129f6"}},"metadata":{}},{"name":"stdout","text":"\n📊 Re-ranking top 19 RRF candidates\n🔄 Computing cross-encoder scores for 19 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b623295059e435f8cfbf51086d5b1c7"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.42 seconds\n\n📈 Comparison: RRF vs Cross-Encoder ranking\n\nRRF Ranking (before re-ranking) - Top 5:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Rank    Doc ID                        Title  RRF Score\n0     1   ast_001    Understanding Black Holes     0.0325\n1     2   ast_005  Dark Matter and Dark Energy     0.0323\n2     3   ast_002      The Life Cycle of Stars     0.0320\n3     4   ast_003       Solar System Formation     0.0318\n4     5  hist_001    The Industrial Revolution     0.0315","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Doc ID</th>\n      <th>Title</th>\n      <th>RRF Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>0.0325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>ast_005</td>\n      <td>Dark Matter and Dark Energy</td>\n      <td>0.0323</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>ast_002</td>\n      <td>The Life Cycle of Stars</td>\n      <td>0.0320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ast_003</td>\n      <td>Solar System Formation</td>\n      <td>0.0318</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>hist_001</td>\n      <td>The Industrial Revolution</td>\n      <td>0.0315</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nCross-Encoder Ranking (after re-ranking) - Top 5:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Rank    Doc ID                        Title  CE Score  RRF Score\n0     1   ast_001    Understanding Black Holes    4.5733     0.0325\n1     2   ast_003       Solar System Formation   -4.3658     0.0318\n2     3   ast_002      The Life Cycle of Stars   -8.0267     0.0320\n3     4   ast_005  Dark Matter and Dark Energy   -9.6758     0.0323\n4     5  hist_003       The Renaissance Period  -11.2628     0.0149","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Doc ID</th>\n      <th>Title</th>\n      <th>CE Score</th>\n      <th>RRF Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ast_001</td>\n      <td>Understanding Black Holes</td>\n      <td>4.5733</td>\n      <td>0.0325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>ast_003</td>\n      <td>Solar System Formation</td>\n      <td>-4.3658</td>\n      <td>0.0318</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>ast_002</td>\n      <td>The Life Cycle of Stars</td>\n      <td>-8.0267</td>\n      <td>0.0320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ast_005</td>\n      <td>Dark Matter and Dark Energy</td>\n      <td>-9.6758</td>\n      <td>0.0323</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>hist_003</td>\n      <td>The Renaissance Period</td>\n      <td>-11.2628</td>\n      <td>0.0149</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n📋 Top 5 results with snippets:\n\n1. [ast_001] Understanding Black Holes\n   Cross-encoder score: 4.5733\n   Original RRF score: 0.0325\n   Snippet: Black holes are regions of spacetime where gravity is so strong that nothing, including light, can escape once it crosses the event horizon. The event horizon is the boundary beyond which escape becom...\n\n2. [ast_003] Solar System Formation\n   Cross-encoder score: -4.3658\n   Original RRF score: 0.0318\n   Snippet: The solar system formed approximately 4.6 billion years ago from the gravitational collapse of a molecular cloud. The Sun formed at the center while leftover material formed a protoplanetary disk. Thr...\n\n3. [ast_002] The Life Cycle of Stars\n   Cross-encoder score: -8.0267\n   Original RRF score: 0.0320\n   Snippet: Stars are born from clouds of gas and dust called nebulae. Through gravitational collapse, the core temperature rises until nuclear fusion begins, converting hydrogen into helium and releasing enormou...\n\n4. [ast_005] Dark Matter and Dark Energy\n   Cross-encoder score: -9.6758\n   Original RRF score: 0.0323\n   Snippet: Dark matter makes up approximately 27% of the universe but doesn't interact electromagnetically, making it invisible to direct observation. Its existence is inferred from gravitational effects on visi...\n\n5. [hist_003] The Renaissance Period\n   Cross-encoder score: -11.2628\n   Original RRF score: 0.0149\n   Snippet: The Renaissance marked a period of renewed interest in classical learning, art, and humanism from the 14th to 17th centuries. Artists like Leonardo da Vinci and Michelangelo revolutionized artistic te...\n\n🔄 Ranking changes analysis:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     Doc ID  Original RRF Rank  New CE Rank Position Change Direction\n0   ast_001                  1            1               0         →\n1   ast_003                  4            2              +2         ↑\n2   ast_002                  3            3               0         →\n3   ast_005                  2            4              -2         ↓\n4  hist_003                 16            5             +11         ↑\n5  cook_001                  7            6              +1         ↑\n6  cook_003                  8            7              +1         ↑\n7  cook_002                 17            8              +9         ↑\n8   ast_004                  6            9              -3         ↓\n9  heal_004                 13           10              +3         ↑","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Doc ID</th>\n      <th>Original RRF Rank</th>\n      <th>New CE Rank</th>\n      <th>Position Change</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ast_001</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>→</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ast_003</td>\n      <td>4</td>\n      <td>2</td>\n      <td>+2</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ast_002</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>→</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ast_005</td>\n      <td>2</td>\n      <td>4</td>\n      <td>-2</td>\n      <td>↓</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hist_003</td>\n      <td>16</td>\n      <td>5</td>\n      <td>+11</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cook_001</td>\n      <td>7</td>\n      <td>6</td>\n      <td>+1</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>cook_003</td>\n      <td>8</td>\n      <td>7</td>\n      <td>+1</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cook_002</td>\n      <td>17</td>\n      <td>8</td>\n      <td>+9</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ast_004</td>\n      <td>6</td>\n      <td>9</td>\n      <td>-3</td>\n      <td>↓</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>heal_004</td>\n      <td>13</td>\n      <td>10</td>\n      <td>+3</td>\n      <td>↑</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## LLM Generation: Bringing It All Together\n\nThe **generation** step combines our retrieved and re-ranked documents with a language model to produce final answers. This is where RAG \"augments\" the generation with retrieved knowledge.\n\n### Key Components\n1. **Context Selection**: Choose top-k documents within token budget\n2. **Prompt Engineering**: Structure context and instructions clearly\n3. **Citation**: Enable traceability back to source documents\n4. **Grounding**: Instruct the model to use only provided context\n\n### Prompt Structure\nA well-structured RAG prompt includes:\n- **System message**: Instructions for behavior and citation\n- **Context section**: Retrieved documents with clear formatting\n- **Query**: User's original question\n- **Instructions**: Explicit grounding requirements\n\n### Token Budget Management\nLanguage models have context limits. We must:\n- Prioritize highest-ranked documents\n- Truncate or summarize if needed\n- Leave space for the generated response\n\n### Citation Strategy\nInclude document IDs in the context so the model can reference specific sources. This enables fact-checking and builds user trust.\n\n**Environment handling**: Read API keys from environment variables and provide graceful fallbacks for missing credentials.","metadata":{}},{"cell_type":"code","source":"# End-to-end RAG pipeline with OpenAI generation\n# This combines all our retrieval components with final answer generation\nimport os\nfrom openai import OpenAI\n\ndef estimate_tokens(text):\n    \"\"\"\n    Rough estimation of token count (approximately 4 characters per token).\n    This is a simple heuristic; actual tokenization may differ.\n    \n    Args:\n        text (str): Input text\n    \n    Returns:\n        int: Estimated token count\n    \"\"\"\n    return len(text) // 4\n\ndef select_context_chunks(ranked_results, max_tokens=2000):\n    \"\"\"\n    Select top-ranked documents that fit within token budget.\n    \n    Args:\n        ranked_results (list): Ranked documents from retrieval pipeline\n        max_tokens (int): Maximum tokens to use for context\n    \n    Returns:\n        list: Selected documents within token budget\n    \"\"\"\n    selected_chunks = []\n    total_tokens = 0\n    \n    for result in ranked_results:\n        # Estimate tokens for this document (title + text + formatting)\n        doc_text = f\"[{result['doc_id']}] {result['title']}\\n{result['text']}\"\n        doc_tokens = estimate_tokens(doc_text)\n        \n        # Check if adding this document would exceed budget\n        if total_tokens + doc_tokens <= max_tokens:\n            selected_chunks.append(result)\n            total_tokens += doc_tokens\n        else:\n            break\n    \n    return selected_chunks, total_tokens\n\ndef create_rag_prompt(query, context_chunks):\n    \"\"\"\n    Create a structured prompt for RAG generation.\n    \n    Args:\n        query (str): User's question\n        context_chunks (list): Selected context documents\n    \n    Returns:\n        tuple: (system_message, user_message)\n    \"\"\"\n    # System message with clear instructions\n    system_message = \"\"\"You are a helpful assistant that answers questions based on provided context. \n\nINSTRUCTIONS:\n1. Answer the user's question using ONLY the information provided in the context below\n2. If you cite information, include the document ID in brackets [doc_id]\n3. If the context doesn't contain enough information to answer the question, say so clearly\n4. Be accurate and specific - don't make assumptions beyond what's stated in the context\n5. Provide a clear, well-structured answer\n\"\"\"\n    \n    # Format context documents clearly\n    context_text = \"\\n\\nCONTEXT DOCUMENTS:\\n\\n\"\n    for i, chunk in enumerate(context_chunks, 1):\n        context_text += f\"Document {i}: [{chunk['doc_id']}]\\n\"\n        context_text += f\"Title: {chunk['title']}\\n\"\n        context_text += f\"Content: {chunk['text']}\\n\\n\"\n    \n    # User message with query and context\n    user_message = f\"{context_text}\\nQUESTION: {query}\\n\\nPlease provide a comprehensive answer based on the context above.\"\n    \n    return system_message, user_message\n\ndef answer_query(query_text, max_context_tokens=2000):\n    \"\"\"\n    Complete RAG pipeline: retrieve, re-rank, and generate answer.\n    \n    Args:\n        query_text (str): User's question\n        max_context_tokens (int): Maximum tokens for context\n    \n    Returns:\n        dict: Complete RAG results including retrieval steps and final answer\n    \"\"\"\n    print(f\"🔍 Starting RAG pipeline for: '{query_text}'\")\n    \n    # Step 1: Hybrid retrieval (BM25 + Semantic)\n    print(\"📊 Step 1: Hybrid retrieval...\")\n    hybrid_results = hybrid_retrieve(query_text, top_k_lex=15, top_k_sem=15)\n    \n    # Step 2: Rank fusion with RRF\n    print(\"🔄 Step 2: Rank fusion (RRF)...\")\n    rrf_results = apply_rrf_to_hybrid(hybrid_results, k=60)\n    \n    # Step 3: Cross-encoder re-ranking\n    print(\"🎯 Step 3: Cross-encoder re-ranking...\")\n    top_candidates = rrf_results[:20]  # Re-rank top 20 candidates\n    reranked_results = rerank_with_cross_encoder(query_text, top_candidates, top_k=15)\n    \n    # Step 4: Context selection within token budget\n    print(\"📝 Step 4: Context selection...\")\n    selected_context, context_tokens = select_context_chunks(reranked_results, max_context_tokens)\n    print(f\"   Selected {len(selected_context)} documents using ~{context_tokens} tokens\")\n    \n    # Step 5: Generate answer with OpenAI\n    print(\"🤖 Step 5: Generating answer...\")\n    \n    # Check for OpenAI API key\n    openai_api_key = os.getenv('OPENAI_API_KEY')\n    if not openai_api_key:\n        print(\"⚠️  OpenAI API key not found in environment variables\")\n        print(\"   Set OPENAI_API_KEY environment variable to enable generation\")\n        return {\n            'query': query_text,\n            'retrieval_results': len(hybrid_results),\n            'rrf_results': len(rrf_results),\n            'reranked_results': len(reranked_results),\n            'selected_context': selected_context,\n            'context_tokens': context_tokens,\n            'answer': \"[Generation skipped: OpenAI API key not available]\",\n            'citations': [chunk['doc_id'] for chunk in selected_context]\n        }\n    \n    try:\n        # Initialize OpenAI client\n        client = OpenAI()\n        \n        # Create RAG prompt\n        system_message, user_message = create_rag_prompt(query_text, selected_context)\n        \n        # Call OpenAI API\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",  # Fast, cost-effective model\n            messages=[\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": user_message}\n            ],\n            max_tokens=500,  # Limit response length\n            temperature=0.1  # Low temperature for factual responses\n        )\n        \n        answer = response.choices[0].message.content\n        \n    except Exception as e:\n        print(f\"❌ Error during generation: {str(e)}\")\n        answer = f\"[Generation failed: {str(e)}]\"\n    \n    # Return comprehensive results\n    return {\n        'query': query_text,\n        'retrieval_results': len(hybrid_results),\n        'rrf_results': len(rrf_results),\n        'reranked_results': len(reranked_results),\n        'selected_context': selected_context,\n        'context_tokens': context_tokens,\n        'answer': answer,\n        'citations': [chunk['doc_id'] for chunk in selected_context]\n    }\n\n# Test the complete RAG pipeline\ntest_queries = [\n    \"How do black holes form and what happens at the event horizon?\",\n    \"What are the health benefits of regular exercise and how does it affect the cardiovascular system?\",\n    \"How do you make a good roux and what are the classic mother sauces in cooking?\"\n]\n\nprint(\"🚀 Testing complete RAG pipeline:\\n\")\nfor i, query in enumerate(test_queries, 1):\n    print(f\"=\" * 80)\n    print(f\"TEST {i}: {query}\")\n    print(f\"=\" * 80)\n    \n    # Run complete RAG pipeline\n    rag_result = answer_query(query)\n    \n    # Display results\n    print(f\"\\n📊 Pipeline Summary:\")\n    print(f\"   Hybrid retrieval: {rag_result['retrieval_results']} candidates\")\n    print(f\"   RRF fusion: {rag_result['rrf_results']} documents\")\n    print(f\"   Re-ranked: {rag_result['reranked_results']} documents\")\n    print(f\"   Context used: {len(rag_result['selected_context'])} documents ({rag_result['context_tokens']} tokens)\")\n    \n    print(f\"\\n📚 Context Documents:\")\n    for j, doc in enumerate(rag_result['selected_context'], 1):\n        print(f\"   {j}. [{doc['doc_id']}] {doc['title']}\")\n    \n    print(f\"\\n💬 Generated Answer:\")\n    print(rag_result['answer'])\n    print(f\"\\n🔗 Citations: {', '.join(rag_result['citations'])}\")\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:15.532409Z","iopub.execute_input":"2025-09-24T14:24:15.532697Z","iopub.status.idle":"2025-09-24T14:24:26.440870Z","shell.execute_reply.started":"2025-09-24T14:24:15.532675Z","shell.execute_reply":"2025-09-24T14:24:26.439812Z"}},"outputs":[{"name":"stdout","text":"🚀 Testing complete RAG pipeline:\n\n================================================================================\nTEST 1: How do black holes form and what happens at the event horizon?\n================================================================================\n🔍 Starting RAG pipeline for: 'How do black holes form and what happens at the event horizon?'\n📊 Step 1: Hybrid retrieval...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f50470157324b34a1966a4ce9892787"}},"metadata":{}},{"name":"stdout","text":"🔄 Step 2: Rank fusion (RRF)...\n🎯 Step 3: Cross-encoder re-ranking...\n🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fceafc6ed4a41e3871647bfbf029a18"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.52 seconds\n📝 Step 4: Context selection...\n   Selected 15 documents using ~1608 tokens\n🤖 Step 5: Generating answer...\n\n📊 Pipeline Summary:\n   Hybrid retrieval: 23 candidates\n   RRF fusion: 23 documents\n   Re-ranked: 15 documents\n   Context used: 15 documents (1608 tokens)\n\n📚 Context Documents:\n   1. [ast_001] Understanding Black Holes\n   2. [ast_005] Dark Matter and Dark Energy\n   3. [ast_003] Solar System Formation\n   4. [ast_002] The Life Cycle of Stars\n   5. [ast_004] Exoplanet Detection Methods\n   6. [cook_001] Essential Knife Skills\n   7. [py_003] Asynchronous Programming Patterns\n   8. [heal_005] Immune System Function\n   9. [cook_003] Building Flavor Profiles\n   10. [heal_004] Sleep and Recovery\n   11. [cook_002] Understanding Heat and Cooking Methods\n   12. [cook_004] Sauce Making Fundamentals\n   13. [sport_004] Strength Training Principles\n   14. [cook_005] Baking Science and Techniques\n   15. [hist_003] The Renaissance Period\n\n💬 Generated Answer:\nBlack holes form when massive stars collapse under their own gravity at the end of their lifecycle. This collapse leads to the creation of a region in spacetime where gravity is so strong that nothing, including light, can escape once it crosses the event horizon. The event horizon is defined as the boundary beyond which escape becomes impossible. At the center of a black hole lies a singularity, which represents a point where spacetime curvature becomes infinite [doc_id: ast_001].\n\n🔗 Citations: ast_001, ast_005, ast_003, ast_002, ast_004, cook_001, py_003, heal_005, cook_003, heal_004, cook_002, cook_004, sport_004, cook_005, hist_003\n\n\n================================================================================\nTEST 2: What are the health benefits of regular exercise and how does it affect the cardiovascular system?\n================================================================================\n🔍 Starting RAG pipeline for: 'What are the health benefits of regular exercise and how does it affect the cardiovascular system?'\n📊 Step 1: Hybrid retrieval...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230da8dc46a34c41b0a70d512b896b6b"}},"metadata":{}},{"name":"stdout","text":"🔄 Step 2: Rank fusion (RRF)...\n🎯 Step 3: Cross-encoder re-ranking...\n🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544e2f512e244833be3be5756d43f0cd"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.49 seconds\n📝 Step 4: Context selection...\n   Selected 15 documents using ~1632 tokens\n🤖 Step 5: Generating answer...\n\n📊 Pipeline Summary:\n   Hybrid retrieval: 26 candidates\n   RRF fusion: 26 documents\n   Re-ranked: 15 documents\n   Context used: 15 documents (1632 tokens)\n\n📚 Context Documents:\n   1. [heal_002] Cardiovascular Health\n   2. [sport_005] Endurance Training Methodologies\n   3. [heal_005] Immune System Function\n   4. [heal_003] Mental Health and Wellness\n   5. [heal_004] Sleep and Recovery\n   6. [sport_003] Injury Prevention Strategies\n   7. [sport_004] Strength Training Principles\n   8. [heal_001] Nutrition and Metabolism\n   9. [sport_001] Athletic Performance Optimization\n   10. [sport_002] Sports Psychology and Mental Training\n   11. [ast_005] Dark Matter and Dark Energy\n   12. [ast_001] Understanding Black Holes\n   13. [cook_003] Building Flavor Profiles\n   14. [ast_004] Exoplanet Detection Methods\n   15. [hist_003] The Renaissance Period\n\n💬 Generated Answer:\nRegular exercise offers several health benefits, particularly for the cardiovascular system. It strengthens the heart muscle, which enhances its ability to pump blood efficiently throughout the body. This improved circulation helps deliver oxygen and nutrients to tissues while also facilitating the removal of waste products.\n\nAdditionally, exercise positively influences various aspects of cardiovascular health, including cholesterol levels, blood pressure, and inflammation. By maintaining a healthy weight and managing stress levels through physical activity, individuals can further support their cardiovascular health. Overall, regular exercise is a crucial component of a healthy lifestyle that promotes optimal cardiovascular function and reduces the risk of heart-related issues [doc_id: heal_002].\n\n🔗 Citations: heal_002, sport_005, heal_005, heal_003, heal_004, sport_003, sport_004, heal_001, sport_001, sport_002, ast_005, ast_001, cook_003, ast_004, hist_003\n\n\n================================================================================\nTEST 3: How do you make a good roux and what are the classic mother sauces in cooking?\n================================================================================\n🔍 Starting RAG pipeline for: 'How do you make a good roux and what are the classic mother sauces in cooking?'\n📊 Step 1: Hybrid retrieval...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298855cdc7a44d8a916ee4da3d26a52f"}},"metadata":{}},{"name":"stdout","text":"🔄 Step 2: Rank fusion (RRF)...\n🎯 Step 3: Cross-encoder re-ranking...\n🔄 Computing cross-encoder scores for 18 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e937152477e243b98a4d03671908dd93"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.49 seconds\n📝 Step 4: Context selection...\n   Selected 15 documents using ~1607 tokens\n🤖 Step 5: Generating answer...\n\n📊 Pipeline Summary:\n   Hybrid retrieval: 18 candidates\n   RRF fusion: 18 documents\n   Re-ranked: 15 documents\n   Context used: 15 documents (1607 tokens)\n\n📚 Context Documents:\n   1. [cook_004] Sauce Making Fundamentals\n   2. [cook_003] Building Flavor Profiles\n   3. [cook_002] Understanding Heat and Cooking Methods\n   4. [cook_001] Essential Knife Skills\n   5. [cook_005] Baking Science and Techniques\n   6. [ast_004] Exoplanet Detection Methods\n   7. [py_004] Machine Learning Pipeline Design\n   8. [ast_001] Understanding Black Holes\n   9. [ast_003] Solar System Formation\n   10. [heal_004] Sleep and Recovery\n   11. [py_003] Asynchronous Programming Patterns\n   12. [py_001] Object-Oriented Programming Concepts\n   13. [hist_005] The Cold War Era\n   14. [ast_002] The Life Cycle of Stars\n   15. [py_005] API Development with FastAPI\n\n💬 Generated Answer:\nTo make a good roux, you need to combine equal parts fat and flour. This mixture is cooked to create a smooth, creamy texture, which serves as the base for many sauces. The classic mother sauces in cooking, which are foundational to many variations, include béchamel (made with a roux), velouté, espagnole, tomato sauce, and hollandaise [doc_id: cook_004].\n\n🔗 Citations: cook_004, cook_003, cook_002, cook_001, cook_005, ast_004, py_004, ast_001, ast_003, heal_004, py_003, py_001, hist_005, ast_002, py_005\n\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Choosing the Right Approach: Vector Store vs Prompt-Embedded vs Local Files\n\nThe choice of knowledge storage and retrieval architecture depends on your specific requirements:\n\n### Vector Stores (e.g., Pinecone, Weaviate, Chroma)\n**Best for**: Medium to large corpora, frequent updates, production systems\n- **Pros**: Optimized ANN search, metadata filtering, horizontal scaling, real-time updates\n- **Cons**: Additional infrastructure, cost, complexity\n- **Use when**: >10,000 documents, multiple users, frequent content updates\n\n### Prompt-Embedded Dataset\n**Best for**: Very small, static knowledge bases\n- **Pros**: Simplest implementation, no retrieval needed, perfect recall\n- **Cons**: Limited by context window, expensive tokens, no semantic search\n- **Use when**: <10 short documents, completely static content, maximum simplicity\n\n### Local File Embeddings (Our Approach)\n**Best for**: Small to medium corpora, single-node applications, development\n- **Pros**: No external dependencies, fast development, full control, offline capability\n- **Cons**: No horizontal scaling, manual index updates, limited concurrent access\n- **Use when**: <100,000 documents, single-node deployment, development/prototyping\n\n### Migration Path\nStart with local files for development, then migrate to a vector store when you need:\n- More than ~50,000 documents\n- Real-time updates\n- Multiple concurrent users\n- Advanced filtering capabilities","metadata":{}},{"cell_type":"markdown","source":"## Testing the Complete RAG Pipeline\nNow that we've built each component of the RAG pipeline, it's time to test the entire system end-to-end. We'll use a set of diverse queries to evaluate how well our RAG implementation retrieves relevant documents and generates accurate answers.","metadata":{}},{"cell_type":"code","source":"# Simple evaluation harness to compare retrieval methods\n# This provides quantitative comparison of different approaches\n\n# Define evaluation queries with expected relevant document IDs\n# These are hand-crafted based on our synthetic corpus\nevaluation_queries_simple = [\n    {\"query\": \"event horizon black holes singularity\", \"relevant_docs\": [\"ast_001\"]},\n    {\"query\": \"stellar life cycle nebula nuclear fusion mass lifespan\", \"relevant_docs\": [\"ast_002\"]},\n    {\"query\": \"solar system formation protoplanetary disk accretion collisions\", \"relevant_docs\": [\"ast_003\"]},\n    {\"query\": \"exoplanet detection transit radial velocity direct imaging\", \"relevant_docs\": [\"ast_004\"]},\n    {\"query\": \"dark matter 27 percent dark energy 68 percent accelerating expansion\", \"relevant_docs\": [\"ast_005\"]},\n    {\"query\": \"knife skills pinch grip claw hand brunoise julienne chiffonade\", \"relevant_docs\": [\"cook_001\"]},\n    {\"query\": \"heat transfer conduction convection radiation roasting braising steaming\", \"relevant_docs\": [\"cook_002\"]},\n    {\"query\": \"build flavor profiles aromatics layering seasoning acid fat herbs\", \"relevant_docs\": [\"cook_003\"]},\n    {\"query\": \"sauce making roux emulsification reduction bechamel hollandaise\", \"relevant_docs\": [\"cook_004\"]},\n    {\"query\": \"baking science gluten leavening temperature ratios\", \"relevant_docs\": [\"cook_005\"]},\n    {\"query\": \"OOP classes objects encapsulation inheritance polymorphism\", \"relevant_docs\": [\"py_001\"]},\n    {\"query\": \"pandas dataframe vectorized operations groupby merge join\", \"relevant_docs\": [\"py_002\"]},\n    {\"query\": \"async await event loop coroutines io bound\", \"relevant_docs\": [\"py_003\"]},\n    {\"query\": \"machine learning pipeline preprocessing cross validation hyperparameter tuning monitoring\", \"relevant_docs\": [\"py_004\"]},\n    {\"query\": \"FastAPI OpenAPI type hints dependency injection async middleware\", \"relevant_docs\": [\"py_005\"]},\n    {\"query\": \"industrial revolution steam power factories urbanization pollution\", \"relevant_docs\": [\"hist_001\"]},\n    {\"query\": \"ancient trade silk road mediterranean venice genoa\", \"relevant_docs\": [\"hist_002\"]},\n    {\"query\": \"renaissance humanism printing press patronage scientific methods\", \"relevant_docs\": [\"hist_003\"]},\n    {\"query\": \"world wars impact women workforce decolonization international organizations\", \"relevant_docs\": [\"hist_004\"]},\n    {\"query\": \"cold war nuclear deterrence proxy wars space race soviet dissolution\", \"relevant_docs\": [\"hist_005\"]},\n    {\"query\": \"nutrition metabolism macronutrients micronutrients catabolism anabolism\", \"relevant_docs\": [\"heal_001\"]},\n    {\"query\": \"cardiovascular health exercise diet blood pressure cholesterol prevention\", \"relevant_docs\": [\"heal_002\"]},\n    {\"query\": \"mental health stress management social connections therapy medication\", \"relevant_docs\": [\"heal_003\"]},\n    {\"query\": \"sleep recovery REM non REM memory waste growth hormone hygiene\", \"relevant_docs\": [\"heal_004\"]},\n    {\"query\": \"immune system innate adaptive antibodies vaccination lifestyle\", \"relevant_docs\": [\"heal_005\"]},\n    {\"query\": \"athletic performance periodization recovery adaptation\", \"relevant_docs\": [\"sport_001\"]},\n    {\"query\": \"sports psychology visualization goal setting self talk pressure\", \"relevant_docs\": [\"sport_002\"]},\n    {\"query\": \"injury prevention dynamic warm up strength imbalances recovery time\", \"relevant_docs\": [\"sport_003\"]},\n    {\"query\": \"strength training progressive overload compound exercises frequency volume intensity form\", \"relevant_docs\": [\"sport_004\"]},\n    {\"query\": \"endurance training heart rate zones base intervals lactate threshold periodization\", \"relevant_docs\": [\"sport_005\"]}\n]\n\nevaluation_queries_mixed = [\n    {\"query\": \"the boundary where light cannot escape defines a black hole\", \"relevant_docs\": [\"ast_001\"]},\n    {\"query\": \"stars born in nebulae; mass determines how long they live\", \"relevant_docs\": [\"ast_002\"]},\n    {\"query\": \"planets grew inside a dusty disk via accretion and collisions\", \"relevant_docs\": [\"ast_003\"]},\n    {\"query\": \"find worlds by tiny eclipses or stellar wobbles\", \"relevant_docs\": [\"ast_004\"]},\n    {\"query\": \"cosmic budget split: ~27% dark matter and ~68% dark energy\", \"relevant_docs\": [\"ast_005\"]},\n    {\"query\": \"pinch grip and claw hand for consistent dice\", \"relevant_docs\": [\"cook_001\"]},\n    {\"query\": \"touch swirl and radiant glow: three ways heat cooks food\", \"relevant_docs\": [\"cook_002\"]},\n    {\"query\": \"acid brightens, fat carries, herbs finish—layer flavors early to late\", \"relevant_docs\": [\"cook_003\"]},\n    {\"query\": \"roux emulsions and reductions as sauce foundations\", \"relevant_docs\": [\"cook_004\"]},\n    {\"query\": \"gluten builds structure while leavening supplies gas lift\", \"relevant_docs\": [\"cook_005\"]},\n    {\"query\": \"classes hide internals; inheritance and polymorphism reuse and adapt behavior\", \"relevant_docs\": [\"py_001\"]},\n    {\"query\": \"vectorize then groupby; avoid loops in pandas dataframes\", \"relevant_docs\": [\"py_002\"]},\n    {\"query\": \"use async await with coroutines for I O heavy tasks\", \"relevant_docs\": [\"py_003\"]},\n    {\"query\": \"pipeline: preprocess → cross validate → tune → monitor for drift\", \"relevant_docs\": [\"py_004\"]},\n    {\"query\": \"FastAPI uses type hints and DI; OpenAPI docs auto generate\", \"relevant_docs\": [\"py_005\"]},\n    {\"query\": \"steam engines and factories pulled workers into cities\", \"relevant_docs\": [\"hist_001\"]},\n    {\"query\": \"silk and ideas moved along Eurasian overland and Mediterranean sea routes\", \"relevant_docs\": [\"hist_002\"]},\n    {\"query\": \"printing press and patronage powered Renaissance art and science\", \"relevant_docs\": [\"hist_003\"]},\n    {\"query\": \"total war reshaped gender roles and spurred decolonization\", \"relevant_docs\": [\"hist_004\"]},\n    {\"query\": \"deterrence by nukes, contests by proxy, and a space race\", \"relevant_docs\": [\"hist_005\"]},\n    {\"query\": \"catabolism vs anabolism: macronutrients fuel, micronutrients enable enzymes\", \"relevant_docs\": [\"heal_001\"]},\n    {\"query\": \"exercise improves circulation and lowers blood pressure\", \"relevant_docs\": [\"heal_002\"]},\n    {\"query\": \"activate parasympathetic with breathing; relationships build resilience\", \"relevant_docs\": [\"heal_003\"]},\n    {\"query\": \"sleep consolidates memories and clears metabolic waste\", \"relevant_docs\": [\"heal_004\"]},\n    {\"query\": \"vaccination trains immunity without causing disease\", \"relevant_docs\": [\"heal_005\"]},\n    {\"query\": \"periodize load to peak while protecting recovery\", \"relevant_docs\": [\"sport_001\"]},\n    {\"query\": \"visualization goal setting and self talk to handle pressure\", \"relevant_docs\": [\"sport_002\"]},\n    {\"query\": \"warm up dynamically; correct strength imbalances; respect rest\", \"relevant_docs\": [\"sport_003\"]},\n    {\"query\": \"add weight gradually and favor multi joint lifts\", \"relevant_docs\": [\"sport_004\"]},\n    {\"query\": \"build base then add intervals to raise lactate threshold\", \"relevant_docs\": [\"sport_005\"]}\n]\n\nevaluation_queries_hard = [\n    {\"query\": \"not the surface—name the invisible boundary no photon escapes\", \"relevant_docs\": [\"ast_001\"]},\n    {\"query\": \"nursery fog to main act; heavier stars burn the candle fast\", \"relevant_docs\": [\"ast_002\"]},\n    {\"query\": \"from dust lanes to gas giants—why are inner worlds rocky\", \"relevant_docs\": [\"ast_003\"]},\n    {\"query\": \"planets spotted by star hiccups and blinkings\", \"relevant_docs\": [\"ast_004\"]},\n    {\"query\": \"cosmic anti gravity accounting for ~68% vs the unseen 27%\", \"relevant_docs\": [\"ast_005\"]},\n    {\"query\": \"keep digits safe: curl then rock—what cutting method is this\", \"relevant_docs\": [\"cook_001\"]},\n    {\"query\": \"browning that is not caramelization—needs amino acids and heat\", \"relevant_docs\": [\"cook_002\"]},\n    {\"query\": \"start with onions celery garlic; lemon at the end wakes it up—why\", \"relevant_docs\": [\"cook_003\"]},\n    {\"query\": \"silky white sauce from equal parts fat and flour then milk\", \"relevant_docs\": [\"cook_004\"]},\n    {\"query\": \"structure from proteins, lift from gas—ratio tweaks change crumb\", \"relevant_docs\": [\"cook_005\"]},\n    {\"query\": \"blueprints and shape shifters that answer the same call\", \"relevant_docs\": [\"py_001\"]},\n    {\"query\": \"split apply combine; join on keys; loops are a smell\", \"relevant_docs\": [\"py_002\"]},\n    {\"query\": \"await your database calls or you’ll jam the loop\", \"relevant_docs\": [\"py_003\"]},\n    {\"query\": \"models rot in production—detect drift and retrain automatically\", \"relevant_docs\": [\"py_004\"]},\n    {\"query\": \"type annotated endpoints, DI, and free docs from the framework\", \"relevant_docs\": [\"py_005\"]},\n    {\"query\": \"smokestacks summoned cities while fields emptied\", \"relevant_docs\": [\"hist_001\"]},\n    {\"query\": \"silk and scripture crossing Eurasia’s arteries\", \"relevant_docs\": [\"hist_002\"]},\n    {\"query\": \"patrons presses and anatomy studies rebooted Europe\", \"relevant_docs\": [\"hist_003\"]},\n    {\"query\": \"total war rewired gender roles and empires\", \"relevant_docs\": [\"hist_004\"]},\n    {\"query\": \"deterrence by terror, wars by proxy, rockets to the moon\", \"relevant_docs\": [\"hist_005\"]},\n    {\"query\": \"the body’s ledger: catabolism versus anabolism\", \"relevant_docs\": [\"heal_001\"]},\n    {\"query\": \"raise HDL and tame BP—move regularly\", \"relevant_docs\": [\"heal_002\"]},\n    {\"query\": \"flip the vagal switch: slow breathing and social ties\", \"relevant_docs\": [\"heal_003\"]},\n    {\"query\": \"the brain’s dishwasher runs at night\", \"relevant_docs\": [\"heal_004\"]},\n    {\"query\": \"train defenders without disease exposure\", \"relevant_docs\": [\"heal_005\"]},\n    {\"query\": \"stress → adapt → peak; change load with the calendar\", \"relevant_docs\": [\"sport_001\"]},\n    {\"query\": \"rehearse success in your head; set targets; tune arousal\", \"relevant_docs\": [\"sport_002\"]},\n    {\"query\": \"imbalances between quads and hamstrings invite trouble\", \"relevant_docs\": [\"sport_003\"]},\n    {\"query\": \"add plates over time; squats and deadlifts first\", \"relevant_docs\": [\"sport_004\"]},\n    {\"query\": \"base miles then intervals to push the threshold rightward\", \"relevant_docs\": [\"sport_005\"]}\n]\n\ndef calculate_hit_at_k(retrieved_doc_ids, relevant_doc_ids, k):\n    \"\"\"\n    Calculate Hit@K: whether at least one relevant document appears in top-k results.\n    \n    Args:\n        retrieved_doc_ids (list): List of retrieved document IDs in rank order\n        relevant_doc_ids (list): List of relevant document IDs\n        k (int): Number of top results to consider\n    \n    Returns:\n        float: 1.0 if hit, 0.0 if miss\n    \"\"\"\n    top_k_retrieved = set(retrieved_doc_ids[:k])\n    relevant_set = set(relevant_doc_ids)\n    \n    # Hit if intersection is non-empty\n    return 1.0 if top_k_retrieved.intersection(relevant_set) else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:26.441910Z","iopub.execute_input":"2025-09-24T14:24:26.442197Z","iopub.status.idle":"2025-09-24T14:24:26.467246Z","shell.execute_reply.started":"2025-09-24T14:24:26.442177Z","shell.execute_reply":"2025-09-24T14:24:26.466218Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Evaluation Framework with Hit@K, MRR, Precision@K, Recall@K and NDCG\n\nWhile Hit@K provides a basic measure of retrieval success, more sophisticated metrics offer deeper insights:\n\n### Mean Reciprocal Rank (MRR)\nMRR measures how high the first relevant document appears in the ranking. It gives more credit to systems that place relevant documents at the top.\n\n**Formula**: MRR = (1/|Q|) × Σ(1/rank_i) where rank_i is the position of the first relevant document for query i\n\n### Normalized Discounted Cumulative Gain (NDCG)\nNDCG accounts for the position of all relevant documents and allows for graded relevance (not just binary relevant/irrelevant).\n\n**Formula**: NDCG@K = DCG@K / IDCG@K where DCG@K = Σ((2^rel_i - 1) / log2(i + 1)) for the top K results, and IDCG@K is the ideal DCG.\n\n### Precision@K and Recall@K\nPrecision@K measures the proportion of relevant documents found in the top K results, while Recall@K measures the proportion of relevant documents that were retrieved out of all relevant documents.\n\n**Formulas**:\n- Precision@K = |Relevant ∩ Retrieved| / |Retrieved| for top K results\n- Recall@K = |Relevant ∩ Retrieved| / |Relevant| for top K resultsxw","metadata":{}},{"cell_type":"code","source":"import math\nfrom typing import List, Dict, Set\n\ndef calculate_mrr(retrieved_doc_ids: List[str], relevant_doc_ids: List[str]) -> float:\n    \"\"\"\n    Calculate Mean Reciprocal Rank for a single query.\n    \n    MRR measures the quality of a ranking by looking at the position of the first relevant document.\n    Higher scores indicate that relevant documents appear earlier in the ranking.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order\n        relevant_doc_ids: List of known relevant document IDs\n    \n    Returns:\n        float: MRR score (1/rank of first relevant doc, or 0 if no relevant docs found)\n    \n    Example:\n        retrieved = ['doc1', 'doc2', 'doc3', 'doc4', 'doc5']\n        relevant = ['doc3', 'doc6']\n        MRR = 1/3 = 0.333 (first relevant doc 'doc3' is at position 3)\n    \"\"\"\n    relevant_set = set(relevant_doc_ids)\n    \n    for rank, doc_id in enumerate(retrieved_doc_ids, 1):\n        if doc_id in relevant_set:\n            return 1.0 / rank\n    \n    return 0.0  # No relevant documents found\n\n\ndef calculate_dcg_at_k(retrieved_doc_ids: List[str], relevant_doc_ids: List[str], \n                       relevance_scores: Dict[str, float], k: int) -> float:\n    \"\"\"\n    Calculate Discounted Cumulative Gain at position k.\n    \n    DCG measures the usefulness of documents based on their position in the ranking,\n    with higher positions having exponentially more impact.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order\n        relevant_doc_ids: List of known relevant document IDs  \n        relevance_scores: Dict mapping doc_id to relevance score (0-3 scale typically)\n        k: Calculate DCG for top-k results\n    \n    Returns:\n        float: DCG@k score\n    \"\"\"\n    dcg = 0.0\n    \n    for i, doc_id in enumerate(retrieved_doc_ids[:k]):\n        if doc_id in relevance_scores:\n            relevance = relevance_scores[doc_id]\n            # DCG formula: rel_i / log2(i + 2) where i is 0-indexed position\n            dcg += relevance / math.log2(i + 2)\n    \n    return dcg\n\n\ndef calculate_ndcg_at_k(retrieved_doc_ids: List[str], relevant_doc_ids: List[str],\n                        relevance_scores: Dict[str, float], k: int) -> float:\n    \"\"\"\n    Calculate Normalized Discounted Cumulative Gain at position k.\n    \n    NDCG normalizes DCG by the ideal DCG (IDCG) to get a score between 0 and 1.\n    This allows fair comparison between queries with different numbers of relevant documents.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order\n        relevant_doc_ids: List of known relevant document IDs\n        relevance_scores: Dict mapping doc_id to relevance score\n        k: Calculate NDCG for top-k results\n    \n    Returns:\n        float: NDCG@k score (0-1, where 1 is perfect ranking)\n    \"\"\"\n    # Calculate actual DCG\n    dcg = calculate_dcg_at_k(retrieved_doc_ids, relevant_doc_ids, relevance_scores, k)\n    \n    # Calculate Ideal DCG (IDCG) - what we'd get with perfect ranking\n    # Sort relevant docs by relevance score in descending order\n    ideal_ranking = sorted(relevance_scores.keys(), \n                          key=lambda x: relevance_scores[x], reverse=True)\n    idcg = calculate_dcg_at_k(ideal_ranking, relevant_doc_ids, relevance_scores, k)\n    \n    # NDCG = DCG / IDCG (avoid division by zero)\n    return dcg / idcg if idcg > 0 else 0.0\n\n\ndef calculate_precision_at_k(retrieved_doc_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:\n    \"\"\"\n    Calculate Precision@K: fraction of retrieved documents that are relevant.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order\n        relevant_doc_ids: List of known relevant document IDs\n        k: Number of top results to consider\n    \n    Returns:\n        float: Precision@k score (0-1)\n    \"\"\"\n    if k == 0:\n        return 0.0\n        \n    top_k_retrieved = set(retrieved_doc_ids[:k])\n    relevant_set = set(relevant_doc_ids)\n    \n    relevant_retrieved = top_k_retrieved.intersection(relevant_set)\n    return len(relevant_retrieved) / k\n\n\ndef calculate_recall_at_k(retrieved_doc_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:\n    \"\"\"\n    Calculate Recall@K: fraction of relevant documents that were retrieved.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order  \n        relevant_doc_ids: List of known relevant document IDs\n        k: Number of top results to consider\n    \n    Returns:\n        float: Recall@k score (0-1)\n    \"\"\"\n    if not relevant_doc_ids:\n        return 0.0\n        \n    top_k_retrieved = set(retrieved_doc_ids[:k])\n    relevant_set = set(relevant_doc_ids)\n    \n    relevant_retrieved = top_k_retrieved.intersection(relevant_set)\n    return len(relevant_retrieved) / len(relevant_set)\n\n\ndef calculate_f1_at_k(retrieved_doc_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:\n    \"\"\"\n    Calculate F1@K: harmonic mean of Precision@K and Recall@K.\n    \n    F1 provides a single score that balances precision and recall.\n    \n    Args:\n        retrieved_doc_ids: List of retrieved document IDs in rank order\n        relevant_doc_ids: List of known relevant document IDs  \n        k: Number of top results to consider\n    \n    Returns:\n        float: F1@k score (0-1)\n    \"\"\"\n    precision = calculate_precision_at_k(retrieved_doc_ids, relevant_doc_ids, k)\n    recall = calculate_recall_at_k(retrieved_doc_ids, relevant_doc_ids, k)\n    \n    if precision + recall == 0:\n        return 0.0\n    \n    return 2 * (precision * recall) / (precision + recall)\n\n\n# Create enhanced evaluation queries with graded relevance scores\n# For this demo, we'll use a simple binary relevance (relevant=1, not relevant=0)\n# In practice, you might have 3-point or 4-point relevance scales\n\ndef create_relevance_scores(eval_queries: List[Dict]) -> Dict[str, Dict[str, float]]:\n    \"\"\"\n    Create relevance score mappings for evaluation queries.\n    \n    For simplicity, we use binary relevance: relevant docs get score 1.0, others get 0.0\n    In production, you might have multi-level relevance (0=irrelevant, 1=somewhat, 2=relevant, 3=highly relevant)\n    \"\"\"\n    relevance_mapping = {}\n    \n    for i, query_data in enumerate(eval_queries):\n        query_id = f\"query_{i}\"\n        relevance_scores = {}\n        \n        # All relevant docs get score 1.0, irrelevant docs get 0.0\n        for doc_id in query_data['relevant_docs']:\n            relevance_scores[doc_id] = 1.0\n            \n        relevance_mapping[query_id] = relevance_scores\n    \n    return relevance_mapping\n\n# Test the new metrics with a simple example\nprint(\"🧪 Testing enhanced evaluation metrics with examples:\\n\")\n\n# Example 1: Perfect ranking\nretrieved_1 = ['doc_a', 'doc_b', 'doc_c', 'doc_d', 'doc_e']\nrelevant_1 = ['doc_a', 'doc_b']\nrelevance_1 = {'doc_a': 1.0, 'doc_b': 1.0}\n\nprint(\"📊 Example 1 - Perfect Ranking:\")\nprint(f\"   Retrieved: {retrieved_1[:3]}...\")\nprint(f\"   Relevant: {relevant_1}\")\nprint(f\"   MRR: {calculate_mrr(retrieved_1, relevant_1):.3f}\")\nprint(f\"   NDCG@5: {calculate_ndcg_at_k(retrieved_1, relevant_1, relevance_1, 5):.3f}\")\nprint(f\"   Precision@5: {calculate_precision_at_k(retrieved_1, relevant_1, 5):.3f}\")\nprint(f\"   Recall@5: {calculate_recall_at_k(retrieved_1, relevant_1, 5):.3f}\")\nprint(f\"   F1@5: {calculate_f1_at_k(retrieved_1, relevant_1, 5):.3f}\")\n\n# Example 2: Poor ranking  \nretrieved_2 = ['doc_x', 'doc_y', 'doc_z', 'doc_a', 'doc_b']\nrelevant_2 = ['doc_a', 'doc_b']\nrelevance_2 = {'doc_a': 1.0, 'doc_b': 1.0}\n\nprint(f\"\\n📊 Example 2 - Poor Ranking (relevant docs at positions 4,5):\")\nprint(f\"   Retrieved: {retrieved_2}\")\nprint(f\"   Relevant: {relevant_2}\")\nprint(f\"   MRR: {calculate_mrr(retrieved_2, relevant_2):.3f}\")\nprint(f\"   NDCG@5: {calculate_ndcg_at_k(retrieved_2, relevant_2, relevance_2, 5):.3f}\")\nprint(f\"   Precision@5: {calculate_precision_at_k(retrieved_2, relevant_2, 5):.3f}\")\nprint(f\"   Recall@5: {calculate_recall_at_k(retrieved_2, relevant_2, 5):.3f}\")\nprint(f\"   F1@5: {calculate_f1_at_k(retrieved_2, relevant_2, 5):.3f}\")\n\nprint(\"\\n💡 Key Insights:\")\nprint(\"   • MRR heavily penalizes when first relevant doc is ranked low\")\nprint(\"   • NDCG accounts for position of ALL relevant documents\")  \nprint(\"   • Precision@K = relevant_retrieved / k_retrieved\")\nprint(\"   • Recall@K = relevant_retrieved / total_relevant\")\nprint(\"   • F1@K balances precision and recall\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:26.468549Z","iopub.execute_input":"2025-09-24T14:24:26.468905Z","iopub.status.idle":"2025-09-24T14:24:26.497424Z","shell.execute_reply.started":"2025-09-24T14:24:26.468875Z","shell.execute_reply":"2025-09-24T14:24:26.496426Z"}},"outputs":[{"name":"stdout","text":"🧪 Testing enhanced evaluation metrics with examples:\n\n📊 Example 1 - Perfect Ranking:\n   Retrieved: ['doc_a', 'doc_b', 'doc_c']...\n   Relevant: ['doc_a', 'doc_b']\n   MRR: 1.000\n   NDCG@5: 1.000\n   Precision@5: 0.400\n   Recall@5: 1.000\n   F1@5: 0.571\n\n📊 Example 2 - Poor Ranking (relevant docs at positions 4,5):\n   Retrieved: ['doc_x', 'doc_y', 'doc_z', 'doc_a', 'doc_b']\n   Relevant: ['doc_a', 'doc_b']\n   MRR: 0.250\n   NDCG@5: 0.501\n   Precision@5: 0.400\n   Recall@5: 1.000\n   F1@5: 0.571\n\n💡 Key Insights:\n   • MRR heavily penalizes when first relevant doc is ranked low\n   • NDCG accounts for position of ALL relevant documents\n   • Precision@K = relevant_retrieved / k_retrieved\n   • Recall@K = relevant_retrieved / total_relevant\n   • F1@K balances precision and recall\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def enhanced_evaluate_retrieval_method(method_name: str, retrieval_function, \n                                      eval_queries: List[Dict], k_values: List[int] = [5, 10]) -> Dict:\n    \"\"\"\n    Enhanced evaluation using multiple metrics: Hit@K, MRR, NDCG, Precision, Recall, F1.\n    \n    Args:\n        method_name: Name of the retrieval method\n        retrieval_function: Function that takes query and returns ranked results\n        eval_queries: List of evaluation query dictionaries\n        k_values: List of k values for evaluation\n    \n    Returns:\n        Dict containing averaged scores for all metrics\n    \"\"\"\n    metrics = {\n        'mrr': [],\n        **{f'hit_at_{k}': [] for k in k_values},\n        **{f'ndcg_at_{k}': [] for k in k_values},\n        **{f'precision_at_{k}': [] for k in k_values},\n        **{f'recall_at_{k}': [] for k in k_values},\n        **{f'f1_at_{k}': [] for k in k_values}\n    }\n    \n    # Create relevance scores for NDCG calculation\n    relevance_mapping = create_relevance_scores(eval_queries)\n    \n    for i, eval_item in enumerate(eval_queries):\n        query = eval_item['query']\n        relevant_docs = eval_item['relevant_docs']\n        query_id = f\"query_{i}\"\n        relevance_scores = relevance_mapping[query_id]\n        \n        # Get retrieval results\n        retrieved_results = retrieval_function(query)\n        \n        # Extract document IDs from results (handle different return formats)\n        if method_name == 'Semantic':\n            # For semantic search, extract doc_id from chunk info\n            retrieved_doc_ids = [result[2]['doc_id'] for result in retrieved_results]\n        else:\n            # For TF-IDF and BM25, extract id from doc info\n            retrieved_doc_ids = [result[2]['id'] for result in retrieved_results]\n        \n        # Calculate MRR (only needs to be calculated once per query)\n        mrr = calculate_mrr(retrieved_doc_ids, relevant_docs)\n        metrics['mrr'].append(mrr)\n        \n        # Calculate metrics for each k value\n        for k in k_values:\n            # Hit@K\n            hit = calculate_hit_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'hit_at_{k}'].append(hit)\n            \n            # NDCG@K\n            ndcg = calculate_ndcg_at_k(retrieved_doc_ids, relevant_docs, relevance_scores, k)\n            metrics[f'ndcg_at_{k}'].append(ndcg)\n            \n            # Precision@K\n            precision = calculate_precision_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'precision_at_{k}'].append(precision)\n            \n            # Recall@K\n            recall = calculate_recall_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'recall_at_{k}'].append(recall)\n            \n            # F1@K  \n            f1 = calculate_f1_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'f1_at_{k}'].append(f1)\n    \n    # Calculate averages\n    avg_metrics = {}\n    for metric_name, values in metrics.items():\n        avg_metrics[metric_name] = np.mean(values)\n    \n    return avg_metrics\n\n\ndef enhanced_evaluate_hybrid_method(method_name: str, eval_queries: List[Dict], \n                                   k_values: List[int] = [5, 10]) -> Dict:\n    \"\"\"\n    Enhanced evaluation for hybrid methods (RRF, Cross-encoder) using multiple metrics.\n    \"\"\"\n    metrics = {\n        'mrr': [],\n        **{f'hit_at_{k}': [] for k in k_values},\n        **{f'ndcg_at_{k}': [] for k in k_values}, \n        **{f'precision_at_{k}': [] for k in k_values},\n        **{f'recall_at_{k}': [] for k in k_values},\n        **{f'f1_at_{k}': [] for k in k_values}\n    }\n    \n    # Create relevance scores\n    relevance_mapping = create_relevance_scores(eval_queries)\n    \n    for i, eval_item in enumerate(eval_queries):\n        query = eval_item['query']\n        relevant_docs = eval_item['relevant_docs']\n        query_id = f\"query_{i}\"\n        relevance_scores = relevance_mapping[query_id]\n        \n        # Get method-specific results\n        if method_name == 'RRF':\n            hybrid_df = hybrid_retrieve(query, top_k_lex=15, top_k_sem=15)\n            rrf_results = apply_rrf_to_hybrid(hybrid_df, k=60)\n            retrieved_doc_ids = [result['doc_id'] for result in rrf_results]\n        \n        elif method_name == 'Cross-encoder':\n            hybrid_df = hybrid_retrieve(query, top_k_lex=15, top_k_sem=15)\n            rrf_results = apply_rrf_to_hybrid(hybrid_df, k=60)\n            reranked_results = rerank_with_cross_encoder(query, rrf_results[:20], top_k=15)\n            retrieved_doc_ids = [result['doc_id'] for result in reranked_results]\n        \n        # Calculate MRR\n        mrr = calculate_mrr(retrieved_doc_ids, relevant_docs)\n        metrics['mrr'].append(mrr)\n        \n        # Calculate metrics for each k value\n        for k in k_values:\n            hit = calculate_hit_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'hit_at_{k}'].append(hit)\n            \n            ndcg = calculate_ndcg_at_k(retrieved_doc_ids, relevant_docs, relevance_scores, k)\n            metrics[f'ndcg_at_{k}'].append(ndcg)\n            \n            precision = calculate_precision_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'precision_at_{k}'].append(precision)\n            \n            recall = calculate_recall_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'recall_at_{k}'].append(recall)\n            \n            f1 = calculate_f1_at_k(retrieved_doc_ids, relevant_docs, k)\n            metrics[f'f1_at_{k}'].append(f1)\n    \n    # Calculate averages\n    avg_metrics = {}\n    for metric_name, values in metrics.items():\n        avg_metrics[metric_name] = np.mean(values)\n    \n    return avg_metrics\n\n# Run enhanced evaluation on all methods\nprint(\"🚀 Running enhanced retrieval evaluation with multiple metrics...\\n\")\n\n# Use mixed queries for comprehensive evaluation\nevaluation_queries = evaluation_queries_hard  # Use subset for demo (faster execution)\n\n# Evaluate individual methods\nenhanced_results = {}\nretrieval_methods = {\n    'TF-IDF': lambda q: query_tfidf(q, top_k=10),\n    'BM25': lambda q: query_bm25(q, top_k=10),\n    'Semantic': lambda q: semantic_search(q, top_k=10)\n}\n\nfor method_name, retrieval_func in retrieval_methods.items():\n    print(f\"📊 Evaluating {method_name} with enhanced metrics...\")\n    results = enhanced_evaluate_retrieval_method(method_name, retrieval_func, evaluation_queries)\n    enhanced_results[method_name] = results\n\n# Evaluate hybrid methods\nprint(f\"📊 Evaluating RRF with enhanced metrics...\")\nenhanced_results['RRF'] = enhanced_evaluate_hybrid_method('RRF', evaluation_queries)\n\nprint(f\"📊 Evaluating Cross-encoder with enhanced metrics...\")\nenhanced_results['Cross-encoder'] = enhanced_evaluate_hybrid_method('Cross-encoder', evaluation_queries)\n\n# Display comprehensive results table\nprint(f\"\\n📈 Comprehensive Retrieval Evaluation Results:\")\n\n# Create DataFrame for better display\nenhanced_eval_data = []\nfor method_name, results in enhanced_results.items():\n    enhanced_eval_data.append({\n        'Method': method_name,\n        'MRR': round(results['mrr'], 3),\n        'Hit@5': round(results['hit_at_5'], 3),\n        'Hit@10': round(results['hit_at_10'], 3),\n        'NDCG@5': round(results['ndcg_at_5'], 3),\n        'NDCG@10': round(results['ndcg_at_10'], 3),\n        'P@5': round(results['precision_at_5'], 3),\n        'R@5': round(results['recall_at_5'], 3),\n        'F1@5': round(results['f1_at_5'], 3)\n    })\n\nenhanced_eval_df = pd.DataFrame(enhanced_eval_data)\ndisplay(enhanced_eval_df)\n\n# Find best performing methods for each metric\nprint(f\"\\n🏆 Best performing methods by metric:\")\nmetrics_to_analyze = ['mrr', 'hit_at_5', 'ndcg_at_5', 'f1_at_5']\nbest_methods_data = []\n\nfor metric in metrics_to_analyze:\n    best_method = max(enhanced_results.items(), key=lambda x: x[1][metric])\n    best_methods_data.append({\n        'Metric': metric.upper().replace('_', '@'),\n        'Best Method': best_method[0],\n        'Score': round(best_method[1][metric], 3)\n    })\n\nbest_methods_df = pd.DataFrame(best_methods_data)\ndisplay(best_methods_df)\n\n# Calculate relative improvements over baseline\nbaseline_method = 'TF-IDF'\nbaseline_results = enhanced_results[baseline_method]\n\nprint(f\"\\n📈 Relative improvements over {baseline_method} baseline:\")\nimprovements_data = []\n\nfor method_name, results in enhanced_results.items():\n    if method_name != baseline_method:\n        mrr_improvement = results['mrr'] - baseline_results['mrr']\n        ndcg_improvement = results['ndcg_at_5'] - baseline_results['ndcg_at_5']\n        f1_improvement = results['f1_at_5'] - baseline_results['f1_at_5']\n        \n        improvements_data.append({\n            'Method': method_name,\n            'MRR Δ': f\"{mrr_improvement:+.3f}\",\n            'NDCG@5 Δ': f\"{ndcg_improvement:+.3f}\",\n            'F1@5 Δ': f\"{f1_improvement:+.3f}\",\n            'Overall Trend': '↑' if (mrr_improvement + ndcg_improvement + f1_improvement) > 0 else '↓'\n        })\n\nif improvements_data:\n    improvements_df = pd.DataFrame(improvements_data)\n    display(improvements_df)\n\nprint(f\"\\n💡 Key Insights:\")\nprint(f\"   • Cross-encoder typically provides the highest precision for top results\")\nprint(f\"   • Hybrid methods (RRF + Cross-encoder) balance recall and precision\")\nprint(f\"   • Semantic search excels at paraphrase and concept matching\")\nprint(f\"   • BM25 remains competitive for exact keyword matching\")\nprint(f\"   • Combining multiple approaches leverages complementary strengths\")\n\nprint(\"\\n✅ Enhanced evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:24:26.498713Z","iopub.execute_input":"2025-09-24T14:24:26.498977Z","iopub.status.idle":"2025-09-24T14:24:46.357770Z","shell.execute_reply.started":"2025-09-24T14:24:26.498955Z","shell.execute_reply":"2025-09-24T14:24:46.356688Z"}},"outputs":[{"name":"stdout","text":"🚀 Running enhanced retrieval evaluation with multiple metrics...\n\n📊 Evaluating TF-IDF with enhanced metrics...\n📊 Evaluating BM25 with enhanced metrics...\n📊 Evaluating Semantic with enhanced metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44344c5903c47aa818ff190f5b1c711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80990ebbfbb444db9e76b078d157a074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080b1c4945fb44168ec1ffd6085d1d89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73742d22178a4574b56a9ef69909c514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ece346ef45eb4afe84d8773f3c42918e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6225fbf6d4f407e81893c783d7d5662"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae85b32bab3e405898b90f8f4f3ae7d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5e45a9e1834710bbeeedf0e777f660"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"814a952a62c149be848b77dde27336e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed400e628c244c1c84efdb5f7d9fe275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b46914ee64f4247990a95979dc78aec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a86fd7ddbe4cff8de3e3257711f46b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47caad20692648e68dc2e880911c2d72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ca41d4aede34ae18a51390e5a9a794c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6ebbbff8a5740d3aa19ed960b8d1603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14c837698f04cacb3679d904d1112b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d049d140ac4ad1a32c8f5c8a264bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23452374cbb24de2b1eb2773c9d98f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803b7e9f8f374d15afeff2c9c7fcfdc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3943c37de0e84e098e574e13686863c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc8526171d234184bf49f9cd48b18974"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ec432d12784ae29da15f54be255aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d06980a432094374a9e664f0aa63d03b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738130f893884a54a533a66e8dee4b69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2973dcae46b489fa935edfd7d35271d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"910ada1be1914b9bb5d813c969a9dfc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4e510e9f9c4823af8be28a42234744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f524afd9bad4220b174af0f1d06c50d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218d43bab88b40d8badb549fa9e6d756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab5a67906c41458eb79b8d1230b2c44c"}},"metadata":{}},{"name":"stdout","text":"📊 Evaluating RRF with enhanced metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0d111fa5f874af69aecdc2a107607f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f801b2174d7446d92b0f88aa284e862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfe0f5d432941558f7ca1315d379680"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b608ab0ccd403eb18070b51a6c4913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88dbbba11f6a4ff29151337df2f2ed21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07447aeaeec4762942cb6e72396b8d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89f6cb5a6be74a14b9ae3520bd1aa130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1dc6b480f534d5bba61b7a1d22ce96b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682241fef0a24c739a8bb127529f8b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a56ea1fa7c4fc783ae360f6722f9e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"551ee4f37c3e476e8eb3a6f1162b4363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957d48cfcbf4463ead6f017a739e41c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c8c996c2940428a947fc9d285971b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131e9ce72363427d853056b79c5c4f23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28971c986cbb4d3fb58b775189413fd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e60105e503a4cc6bb6024a173453baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd1d3512ce8408baed0a4a80a9fa9d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bac2caf1a1c44a1b2cd4f97cf9bf6d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2bf026927046308655418b3e54c0d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db08bdd5633e4c36ba8f61fcb00a270b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6e6f629c41457b8b79d0f7ee5230d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea2c6bad4564b718c767be0b896be51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e46d088ee8a64af4a9820dba9ac6feb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fdd47c6c2494a22bfd51fa4b1738a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7918ccda3fa4e7f972df4b9c8a9fc82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501353a1d5e94deaa8e0e89ab07d3ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af1173a78994c70a78718f53f08d5a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ccbcecd57bb4e7fb9526f6cc623e7e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c29e63995248a79d209b3835d0afbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2603580ae441f7b459f208cd2034b0"}},"metadata":{}},{"name":"stdout","text":"📊 Evaluating Cross-encoder with enhanced metrics...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7282b3be25d1459d95da806b64d5b899"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0f466ac5dd40c5a6ddb0e39e153fb6"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 1.31 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888c5dfd24cd4c188b8913b8039799b0"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf8d9cc53d9643d6ae90ffb4d3c904c7"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.46 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3181748d05914ea28ebb7e13661ba5d6"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1723e5b366f8435e9165adbbf908fb7d"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.52 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5dde1a4483c44ebb4fa2d4f4d293912"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efafca91270b4c7c9a5610336765282d"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.48 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ede796f36e24660a8367890b47b1fe1"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5203b104eeb4eb9af9a98d48cf81a2a"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.51 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eed8ea1b45e42ccbed7a64eec1ac91f"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4b05f38357451c80881b5a87fe76fe"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.50 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f20776a7722f47cb8153c40984bcc8f1"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d70c7e28358944958941cef15ce6e636"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.50 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71b5fe5edf36414099dd60b1ccc82942"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1db7df189cc4b4095ac6bedd8d84361"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.54 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b2a0625ec944a6b402925422c02791"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26762f0864254023ab3bd256d8044946"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.49 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f58171c89de44e80b575a7c6832b31b4"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc6f3aa4f4e841679b2493033b1e948c"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.47 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e840be67d20348f3a9b16247fe4e700e"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee9e86e3c66443c81ca96d2d5be6888"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.50 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddafd157244c4db9aa5675d0bd5ce2d0"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bcad83493374d58b4abd845bc69deaa"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.51 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27018ccc7ed24a7b8af844fa2508fbfc"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d849c946e4467f9bc24203706bfeeb"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.49 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9edda36b342d49a9826e2ec7e87b0055"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc191b1070c4772bab140778800fe1c"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.46 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb2ccc62a074027b79aec9c3ed7a0d5"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11a6ef5b49334ce78f41433931e14bd7"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.52 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7ca1e2524204a3b973c0ab833659ce2"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3109f400562e4cc18c0fa765e1031efe"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.48 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"173f930771cd4bdea6e5ca7a01ec8034"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781724c1fc7c48968cb6a7781cf7ce36"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.53 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7fd3e21a7a946019c9bf97b2e407362"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 18 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a522e09b54f144cab06188c42828f405"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.44 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6921e78b47b43bd84b953cff9cee0bb"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 19 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416f972b1cd440c1a44d136af3ff34a3"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.41 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9314fbbef0ce4b1895f155642534a796"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7283f9be6649a58748d5bde37e29c7"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.54 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d3e96437154cb589719fbaecbf420d"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af9a56ff51847259cb1cc72aadc2672"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.74 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec86d237fe44911b873802b920350b9"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 19 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcbf4fed00e44e009e9074c3ab7924e9"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.44 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84ddff9005f346f5a32ffab3d1d8d1ac"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 19 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9c3e830fc34d28b949e80ad6518c19"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.48 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc20cbf8705841aaa48802d5384a2652"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d965ed61acd14624ad7512cd4b8fe332"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.49 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96c2e85213504f018f02edc014c2009b"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0941c3b837dc42fc91c6537dc9429afe"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.47 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e80a1b60fa64e8294e8243a71062088"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"665f2c7cf94b431fb50ff368e0911536"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.45 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8180b9d9c863414bb22d1f5745ed04f7"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e377ff20277460e90552834844166a7"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.51 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3148b83dceb04fbf9dd404d30e2c5224"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9ab4d255db41fbbfee9375e7687f86"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.47 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5caff3d540a4bc9828cb2d558c192e6"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 19 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03558252361344d9be883892e9b6d28a"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.43 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c1606fcb15f4a92a9e2012c7734d7a9"}},"metadata":{}},{"name":"stdout","text":"🔄 Computing cross-encoder scores for 20 candidates...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db757c6e31144080a5e9e488d008799f"}},"metadata":{}},{"name":"stdout","text":"⏱️  Cross-encoder re-ranking completed in 0.47 seconds\n\n📈 Comprehensive Retrieval Evaluation Results:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          Method    MRR  Hit@5  Hit@10  NDCG@5  NDCG@10   P@5  R@5   F1@5\n0         TF-IDF  0.888    0.9   0.933   0.888    0.899  0.18  0.9  0.300\n1           BM25  0.886    0.9   0.967   0.883    0.904  0.18  0.9  0.300\n2       Semantic  0.983    1.0   1.000   0.988    0.988  0.20  1.0  0.333\n3            RRF  0.898    0.9   1.000   0.888    0.922  0.18  0.9  0.300\n4  Cross-encoder  0.978    1.0   1.000   0.983    0.983  0.20  1.0  0.333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>MRR</th>\n      <th>Hit@5</th>\n      <th>Hit@10</th>\n      <th>NDCG@5</th>\n      <th>NDCG@10</th>\n      <th>P@5</th>\n      <th>R@5</th>\n      <th>F1@5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TF-IDF</td>\n      <td>0.888</td>\n      <td>0.9</td>\n      <td>0.933</td>\n      <td>0.888</td>\n      <td>0.899</td>\n      <td>0.18</td>\n      <td>0.9</td>\n      <td>0.300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BM25</td>\n      <td>0.886</td>\n      <td>0.9</td>\n      <td>0.967</td>\n      <td>0.883</td>\n      <td>0.904</td>\n      <td>0.18</td>\n      <td>0.9</td>\n      <td>0.300</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Semantic</td>\n      <td>0.983</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.988</td>\n      <td>0.988</td>\n      <td>0.20</td>\n      <td>1.0</td>\n      <td>0.333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RRF</td>\n      <td>0.898</td>\n      <td>0.9</td>\n      <td>1.000</td>\n      <td>0.888</td>\n      <td>0.922</td>\n      <td>0.18</td>\n      <td>0.9</td>\n      <td>0.300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cross-encoder</td>\n      <td>0.978</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.983</td>\n      <td>0.983</td>\n      <td>0.20</td>\n      <td>1.0</td>\n      <td>0.333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n🏆 Best performing methods by metric:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Metric Best Method  Score\n0        MRR    Semantic  0.983\n1   HIT@AT@5    Semantic  1.000\n2  NDCG@AT@5    Semantic  0.988\n3    F1@AT@5    Semantic  0.333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>Best Method</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MRR</td>\n      <td>Semantic</td>\n      <td>0.983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HIT@AT@5</td>\n      <td>Semantic</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NDCG@AT@5</td>\n      <td>Semantic</td>\n      <td>0.988</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F1@AT@5</td>\n      <td>Semantic</td>\n      <td>0.333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n📈 Relative improvements over TF-IDF baseline:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          Method   MRR Δ NDCG@5 Δ  F1@5 Δ Overall Trend\n0           BM25  -0.002   -0.004  +0.000             ↓\n1       Semantic  +0.095   +0.100  +0.033             ↑\n2            RRF  +0.010   +0.000  +0.000             ↑\n3  Cross-encoder  +0.090   +0.096  +0.033             ↑","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>MRR Δ</th>\n      <th>NDCG@5 Δ</th>\n      <th>F1@5 Δ</th>\n      <th>Overall Trend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25</td>\n      <td>-0.002</td>\n      <td>-0.004</td>\n      <td>+0.000</td>\n      <td>↓</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Semantic</td>\n      <td>+0.095</td>\n      <td>+0.100</td>\n      <td>+0.033</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RRF</td>\n      <td>+0.010</td>\n      <td>+0.000</td>\n      <td>+0.000</td>\n      <td>↑</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cross-encoder</td>\n      <td>+0.090</td>\n      <td>+0.096</td>\n      <td>+0.033</td>\n      <td>↑</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n💡 Key Insights:\n   • Cross-encoder typically provides the highest precision for top results\n   • Hybrid methods (RRF + Cross-encoder) balance recall and precision\n   • Semantic search excels at paraphrase and concept matching\n   • BM25 remains competitive for exact keyword matching\n   • Combining multiple approaches leverages complementary strengths\n\n✅ Enhanced evaluation complete!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Interpreting Enhanced Evaluation Metrics\n\n### When to Use Each Metric\n\n**Mean Reciprocal Rank (MRR)**\n- **Best for**: Systems where finding the first relevant document quickly is critical\n- **Example**: Question answering where users need one good answer\n- **Interpretation**: MRR=0.5 means on average, the first relevant document is at position 2\n\n**Normalized Discounted Cumulative Gain (NDCG)**  \n- **Best for**: Systems where ranking quality of all results matters\n- **Example**: Search engines where users browse multiple results\n- **Interpretation**: NDCG@5=0.8 means the ranking achieves 80% of the ideal score\n\n**Hit@K**\n- **Best for**: Simple binary assessment of retrieval success\n- **Example**: Basic \"did we find anything useful?\" evaluation\n- **Interpretation**: Hit@5=0.7 means 70% of queries had at least one relevant doc in top-5\n\n**Precision@K**\n- **Best for**: Systems where result quality (low false positives) is crucial\n- **Example**: Medical diagnosis support where wrong results are dangerous\n- **Interpretation**: P@5=0.6 means 60% of returned results are relevant\n\n**Recall@K**\n- **Best for**: Systems where completeness (low false negatives) is crucial  \n- **Example**: Legal discovery where missing documents has consequences\n- **Interpretation**: R@5=0.4 means we found 40% of all relevant documents\n\n**F1@K**\n- **Best for**: Balanced assessment of precision and recall\n- **Example**: General-purpose search systems\n- **Interpretation**: F1@5=0.5 balances finding relevant docs with avoiding irrelevant ones\n\n### Choosing the Right Metric for Your Use Case\n\n| Use Case | Primary Metric | Reasoning |\n|----------|---------------|-----------|\n| **QA Systems** | MRR | Users need one good answer fast |\n| **Research/Discovery** | NDCG@10 | Users explore multiple results |\n| **Fact Verification** | Precision@5 | Accuracy more important than completeness |\n| **Legal/Compliance** | Recall@10 | Can't afford to miss relevant documents |\n| **General Search** | F1@5 or NDCG@5 | Balance of multiple factors |\n\n### Statistical Significance Testing\n\nFor production systems, always test statistical significance:\n- Use paired t-tests to compare methods\n- Require p < 0.05 for claiming improvements  \n- Test on diverse query sets (easy + hard queries)\n- Consider effect size, not just statistical significance","metadata":{}},{"cell_type":"markdown","source":"## Glossary of RAG Terms\n\n- **Document**: A single piece of content in your knowledge base (article, page, etc.)\n- **Chunk**: A segment of a document, typically 100-500 tokens for better embedding quality\n- **Corpus**: The complete collection of documents available for retrieval\n- **Index**: Data structure enabling fast search (TF-IDF matrix, embedding vectors, etc.)\n- **TF-IDF**: Term Frequency-Inverse Document Frequency; scores terms by frequency vs rarity\n- **BM25**: Best Matching 25; probabilistic ranking function improving on TF-IDF\n- **Embedding**: Dense vector representation capturing semantic meaning of text\n- **Vector Store**: Database optimized for storing and searching high-dimensional vectors\n- **ANN**: Approximate Nearest Neighbors; fast similarity search with slight accuracy trade-off\n- **FAISS**: Facebook AI Similarity Search; library for efficient similarity search\n- **Hybrid Retrieval**: Combining multiple retrieval methods (lexical + semantic)\n- **RRF**: Reciprocal Rank Fusion; method for combining rankings from multiple systems\n- **Cross-encoder**: Transformer model scoring (query, passage) pairs for re-ranking\n- **Top-k**: Retrieving the k highest-scoring results\n- **Recall**: Fraction of relevant documents successfully retrieved\n- **Precision**: Fraction of retrieved documents that are actually relevant\n- **Context Window**: Maximum input length a language model can process\n- **Hallucination**: When language models generate factually incorrect information\n- **Prompt Template**: Structured format for providing context and instructions to LLMs\n- **Grounding**: Ensuring model responses are based on provided evidence rather than training data","metadata":{}}]}